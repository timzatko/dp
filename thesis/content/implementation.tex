\chapter{Implementácia}

\section{Metóda RISEI}

Metódu RISEI sme sa rozhodli implementovať v jazyku Python, keďže plánujeme používať knižnice pre strojové učenie akými sú \textit{tensorflow} či \textit{scikit-learn}.

\subsection{Generovanie masiek}

Na základe BPMN diagramu (Obr. \ref{fig:risei_diagram}) sme implementovali proces generovania masiek. Generovanie masiek prebieha paralelne vo viacerých procesoch použitím knižnice \textit{multiprocessing}. Metóda RISEI síce pracuje s trojrozmernými dátami, avšak diagramy v tejto sekcii zobrazujú snímky a masky v 2D (konkrétne určitú vrstvu z 3D snímku) kvôli jednoduchšej vizualizácii. V tejto sekcii popíšeme jednotlivé kroky generovania masiek.

\paragraph{Vytvorenie náhodnej binárnej masky}

Náhodné binárne masky generujeme pomocou knižnice \textit{numpy}. Pomocou nasledovného kódu vygenerujeme $N$ náhodných masiek 3D binárnych matice. Obr. \label{fig:binary_mask} zobrazuje takúto binárnu maticu, ale v 2D. \textit{size} (veľkosť) a \textit{probability} (pravdepodobnosť) sú hyper-parametrami RISEI metódy. \textit{size} hovorí o veľkosti generovanej masky, čím je toto číslo väčšie tým bude výsledná maska viac fragmentovaná na malé plochy. \textit{probability} hovorí o tom, s akou pravdepodobnosťou daná plocha neprekrytá maskou. Metóda RISE, z ktorej vychádzame používa predvolenú hodnotu \textit{size = 8}, preto sme použili rovnakú hodnotu.

\begin{lstlisting}
    binary_masks = np.random.rand(N, size, size, size) < probability
\end{lstlisting}

\begin{figure}[H]
    \centering
    \includegraphics[width=13cm]{assets/images/binary_mask.png}
    \caption{Porovnanie dvoch binárnych masiek s rôznou veľkosťou (\textit{size}), čím väčšia veľkosť, tým je obrázok viac fragmentovaný. Keď je fragmentácia vyššia, zakrývame menšie časti mozgu, predpokladáme, že takto sa nám nepodarí zakryť relevantné časti z čo zapríčiní nižšiu kvalitu tepelnej mapy (predpokladáme, že v takomto prípade bude ''teplo'' rovnomerne rozmiestnené po celej snínke).}
    \label{fig:binary_mask}
\end{figure}

\paragraph{Náhodné nastavenie pozície vyrezania, zväčšenie binárnej masky a orezenie na veľkosť obrázka}

Binárnu masku zväčšíme na veľkosť vstupnej snímky plus menší offset (o veľkosti size). Následne zo zväčšenej masky na náhodnej pozícii vyrežeme masku o veľkosti vstupnej snímky (Obr. \ref{fig:binary_mask_resized}). Táto maska určuje, ktoré miesta na snímke je potrebné dokresliť (biele miesta sú určené na dokreslenie). Tento krok v pôvodnej implementácii RISE nie je.

\begin{figure}[H]
    \centering
    \includegraphics[width=13cm]{assets/images/binary_mask_resized.png}
    \caption{Vygenerovaná maska je zväčšená a orezaná na veľkosť vstupnej snímky (o veľkosti $[104, 128, 104]$ pričom na obrázkoch je vizualizovaná druhá a tretia dimenzia). Úplne vľavo je binárna maska o veľkosti $8$. V strede je invertovaná binárna maska (kvôli ďaľšiemu pracovanou s ňou) a vpravo je orezaná binárna maska o veľkosti vstupnej snímky.}
    \label{fig:binary_mask_resized}
\end{figure}

\paragraph{Zväčšenie pomocou bilineárnej interpolácie a orezanie masky na veľkosť obrázka}

Tak ako v poôvodnej implementácii RISE, vytárame ''čiernu'' masku na zakrytie častí obrázku. Pôvodnú binárnu masku pomocou bilineárnej interpolácie (funkcia \textit{resize} z knižnice \textit{scikit-learn}) zväčšujeme na veľkost o niečo väčšiu ako je vstupná snímka (aby sme mohli vykonať náhodný posun), následne vyrežeme na náhodnej pozícii masku o veľkosti vstupnej snímky (táto náhodná pozícia je rovnaká ako pri orezávani binárnej masky bez interpolácie, preto je v BPMN diagrame v samostatnom kroku).

\begin{figure}[H]
    \centering
    \includegraphics[width=13cm]{assets/images/interpolated_mask.png}
    \caption{Vygenerovaná maska je zväčšená pomocou bilineárnej interpolácie a orezaná na veľkosť vstupnej snímky (tá je o veľkosti $[104, 128, 104]$ pričom na obrázkoch je vizualizovaná druhá a tretia dimenzia). Úplne vľavo je binárna maska o veľkosti $8$. V strede je invertovaná binárna maska (kvôli ďaľšej práci s ňou) a vpravo je orezaná interpolovaná ''čierna'' maska o veľkosti vstupnej snímky.}
    \label{fig:interpolated_mask}
\end{figure}

\paragraph{Prekrytie masky s obrázkom a dokreslenie zamaskovaných častí obrázka}

Keďže pracujeme nad trojrozmernými dátami, pokúsili sme sa použiť dokreslovanie obrázka v 3D. Na to sme sa pokúsili použiť funkciu \textit{inpaint} s knižnice \textit{scikit-image}, avšak dokreslenie jednej masky bolo veľmi časovo náročné (trvanie bolo až v minútach kde dokreslenie v 2D je v sekundách) pričom v rámci navrhovanej metódy je ich potrebné generovať tisíce, preto sme od trojrozmerného dokreslovania upustili.

Dokreslovanie dvojrozmerných snímok z 3D snímku má avšak svoje nevýhody. Nech máme snímky o veľkosti $[z, y, x]$, pri 2D dokreslení musíme dokreslovať $z$ snímok o veľkosti $[y, x]$ (alebo $y$ snímok o veľkosti $[y, x]$, alebo $x$ snímok o veľkosti $[y, z]$). Pri takomto dokresľovaní, dokreslenie z pohľadu $[y, x]$ vyzerajú byť správne, avšak z iného pohľadu, napr. $[z, x]$ sa javí byť dokreslenie nesprávne, najmä kvôli vzniknutým ostrým hranám (Obr. \ref{fig:inpaint_3x_2d}). Tento problém sme adresovali tak, že dokreslovanie vykonávame vo všetkých troch rovinách a následne počítame priemer pre každý voxel zo všetkých troch dokreslení. Takto je výsledok o niečo lepší, tj. z každej strany je dokreslenie lepšie ako nesprávne dokreslenie z 2D ale o niečo horšie ako správne dokreslenie z 2D. Na označenie miest, ktoré treba dokresliť sme použili zväčšenú binárnu masku (Obr. \ref{fig:binary_mask_resized}). Dokreslenie vykonávame funkciou \textit{inpaint} z knižnice \textit{cv2 (Open CV)}. Používame dokreslovací algoritmus \textit{cv2.INPAINT\_TELEA}, keďže pomocou neho sme dosahovali vizuálne najlepšie výsledky. Funkcia \textit{cv2.inpaint} vyžaduje ako parameter \textit{inpaint\_radius} (Obr. \ref{fig:inpaint_radius}), čo je jedným z hyper parametrov našej metódy.

\begin{figure}[H]
    \centering
    \includegraphics[width=13cm]{assets/images/inpaint_3x_2d.png}
    \caption{Porovnanie 2D dokreslenia (iba v jednej dimenzii) a spriemerovaného 3x 2D dokreslenia (v každej dimenzii). Použitie iba 2D dokreslenia je kvalitné iba v jednej dimenzii a v ostatných je deštruktívne - vytvára ostré hrany. Použitie 3x 2D dokreslenia a spriemerovanie pre každý voxel produkuje primerane dobré dokreslenia po pohľade z každej dimenzie.}
    \label{fig:inpaint_3x_2d}
\end{figure}

Keďže sa pôvodná implementácia RISE prekrýva miesta tak, aby nevznikali ostré hrany medzi zakrytým miestom a pôvodným obrázkom, a teda vznikol plynulý prechod, aj pri dokreslení vytvárame plynulý prechod medzi dokresleným a pôvodným obrázkom (Obr. \ref{fig:inpaint_soft_corners}). Tento prechod je implementovaný nasledovne.

\begin{lstlisting}
    # binary_mask int[z, x, y] - upsized binary mask
    # image float[z, x, y] - original image
    # mask float[z, x, i] - upsizded and interpolated binary mask
    # inpaint_radius int
    inpainted = cv.inpaint(image, binary_mask, inpaint_radius, cv2.INPAINT_TELEA)
    inpainted_blend = image * mask + inpainted * (1 - mask)
\end{lstlisting}

\begin{figure}[H]
    \centering
    \includegraphics[width=10cm]{assets/images/inpaint_soft_corners.png}
    \caption{Príklad vyhladzovania hrán dokreslenia - splynutie dokreslenia s pôvodným snímkom (štvrtá snímka). Druhá snímka zobrazuje ostré hrany po dokreslení - bez splývania s obrázkom. Piata snímka zobrazuje rozdielový obrázok medzi oboma prístupmi. Môžeme si všimnúť, že na obrázku sú viditeľné miesta, kde sa nachádza prechod na interpolovanej binárnej maske. O tieto miesta (informácie) je dokreslenie s vyhladenými hranami ''bohatšie''.}
    \label{fig:inpaint_soft_corners}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=13cm]{assets/images/inpaint_radius.png}
    \caption{Porovnanie okruhov dokreslenia (parameter \textit{inpaint\_radius}), rozdiel vo výsledku nie je veľmi viditelný, avšak s väčśím oruhom dokreslenia je generovanie rádovo pomalšie. (pri generovaní bolo vypnuté splynutie dokreslenia so snímkom aby bol rozdiel aspoň trochu viditeľný)}
    \label{fig:inpaint_radius}
\end{figure}

\paragraph{Prekrytie dokreslenej masky a čiernej masky s obrázkom}

Keďže v rámci metódy sa prekrývajú tri rôzne vrstvy - originálna snímka, čierna maska a dokreslená snímka, môžeme tieto vrstvy skombinovať v rôznom pomere a tým vytvoriť novú snímku.

Toto sme implementovali zavedením parametrov $b1$ a $b2$ (skratka od slova prechod, angl. blend), ktoré hovoria o pomere medzi originálnou snímkou a dokreslenou snímkou, a originálnou snímkou spojenou s dokreslením a čiernou maskou (Obr. \ref{fig:risei_layers}). Pri týchto parametroch platí, že $0 <= b1, b2 <= 1$. Takto zadefinované parametre mi umožňujú vytvoriť zakaskovaný snímok iba s čiernou maskou ($b1 = 0$, $b2 = 1$) či iba s dokreslením ($b1 = 1$, $b2 = 0$).

\begin{figure}[H]
    \centering
    \includegraphics[width=13cm]{assets/images/risei_layers.png}
    \caption{Príklad, ako vyzerá spojenie originálnej snímky, dokreslenej snímky a čiernej masky. V diagrame je zobrazený aj výsledok medzikroku spojenia dokreslenej snímky a pôvodnej snímky. Parametre boli nastavené na $b1 = 0.75$ a $b2 = 0.75$.}
    \label{fig:risei_layers}
\end{figure}

Názov ''čierna'' maska pochádza z pôvodnej implementácie RISE, kde sa obrázok prekrýval čiernou maskou. V našej implementácii neprekrývame farbou, ale hodnotou, tj. ''čierna'' je hodnota $0$ (minimum). Okrem použitia hodnoty $0$, môžeme použiť aj $1$, \textit{priemer} či \textit{medián} (toto je ďaľším hyper-parametrom našej metódy). Zjednodušená (a menej efektívna, v produkčej implementácii sa niektoré inštrukcie nevykonávajú keď \textit{b1} je 0 alebo \textit{b2} je 0) implementácia spojenia jednotlivých vrstiev vyzerá nasledovne.

\begin{lstlisting}
    # image float[z, x, y] - original image
    # inpainted_blend float[z, x, y] - inpainted image
    # mask float[z, x, i] - upsizded and interpolated binary mask
    # b1 float <0, 1>
    # b2 float <0, 1>
    # b2_value string - what value use in "black" mask (min/max/mean/median)

    # merge with inpainted image
    new_image = (1 - b1) * original_image + b1 * inpainted_blend

    value = 0 # black
    if b2_value == 'max':
        value = 1 # white
    elif b2_value == 'mean':
        value = np.mean(original_image)
    elif b2_value == 'median':
        value = np.median(original_image)
    # merge with "black" mask
    new_image = b2 * mask * new_image + (b2 * (1 - mask) * value)
\end{lstlisting}

Kompletný zoznam parametrov metódy RISEI sa nachádza v tabuľke \ref{tab:risei_params}.

\begin{table}[H]
    \begin{tabular}{p{0.25\linewidth} | p{0.15\linewidth} | p{0.5\linewidth}}
        \hline
        Názov             & Dátový typ & Popis                                                               \\ \hline
        s                 & int        & Veľkosť strany binárnej 3D matice.                                        \\
        p                 & float      & Pravdepodobnosť, že plocha nebude prekrytá maskou.                        \\
        b1                & float      & Miera prekrytia medzi originálnym snímkom a dokresleným snímkom.          \\
        b2                & float      & Miera prekrytia s ''čiernou'' maskou.                                     \\
        b2\_value         & string     & Hodnota ''čiernej'' masky, môže to byť minimum, maximum, medián, priemer. \\
        in\_paint\_radius & float      & Polomer dokreslenia algoritmom z knižnice OpenCV.                         \\ \hline
    \end{tabular}
    \caption{Zoznam parametrov metódy RISEI.}
    \label{tab:risei_params}
\end{table}

\subsection{Vytvorenie tepelných máp}

Na základe návrhu (Sekcia \ref{sec:risei}) sme implementovali vytváranie tepelných máp. Keďže generovanie tepelnej mapy si vyžaduje vygenerovať veľký počet zamaskovaných snímok, ktoré v istom momente musia byť všetky uložené v pamäti, generujeme a vyhodnocujeme zamaskované snímky v dávkach (angl. batch). Zdrojový kód nižšie, implementuje vytvorenie jednej tepelnej mapy. Príklad vytvorenej tepelnej mapy uvádzame na obrázku \ref{fig:heatmap_example}.

\begin{lstlisting}
# image_x float[z, x, y, 1] - original image
# masks_count int - how many masks are generated to create a heatmap
# batch_size - how many masks to evaluate on model
# risei_batch_size int - how many masks to generate in one batch
# seed int int - seed for mask generation
# cls_idx int - index of target class in model output vector
# model tf.keras.Model - instance of tensorflow model

risei = RISEI(s=8, p=0.5, b1=0.5, b2=0.5, b2_value='median', in_paint_radius=5)
heatmap = np.zeros(shape=image_x.shape[:3])
batch_count = math.ceil(masks_count / risei_batch_size)
weights = 0

for batch_idx in range(batch_count):
    batch_masks_count = min(risei_batch_size, masks_count - batch_idx * risei_batch_size)
    # reshape input for RISEI since it works with [z, y, x] shape
    # batch_x float[z, x, y] - images to evaluate with masks already applied
    # masks float[z, x, y] - interpolated binary masks (so we know which places we inpainted or masked)
    batch_x, masks = risei.generate_masks(batch_masks_count, image_x.reshape(image_x.shape[:3]), seed=seed)
    y_pred_batch_x = model.predict(batch_x.reshape((-1, *image_x.shape)), batch_size=batch_size)

    for mask, y_pred in zip(masks, y_pred_batch_x):
        # invert the mask, since 1 is for no masking
        # y_pred is the activation for the input masked image on last layer (softmax)
        heatmap = heatmap + y_pred[cls_idx] * (1 - mask)
        weights += y_pred[cls_idx]

heatmap = heatmap / weights
\end{lstlisting}

\begin{figure}[h!]
    \centering
    \includegraphics[width=10cm]{assets/images/heatmap_example.png}
    \caption{Príklad vytvorenej tepelnej mapy (vpravo) k MRI snímke (vľavo). Mierka vujadruje priemernú mieru aktivácie pre daný voxel.}
    \label{fig:heatmap_example}
\end{figure}

\subsection{Vyhodnotenie tepelných máp}

Zatiaľ sme implementovali, podľa návrhu riešenia (Sekcia \ref{sec:evaluation_design_method_quality}), iba metriky \textit{insertion} a \textit{deletion}.

\subsubsection{Metriky insertion \& deletion \label{sec:insertion_deletion}}

Tieto metriky fungujú tak, že postupne odstraňujeme/pridávame pixely z obrázku a tieto obrázky vkladáme do modelu a zaznamenávame si aktiváciu na poslednej vrstve pre predikovanú triedu. V prípade obrázkov, a teda dvojrozmerných dát je to ešte výpočtovo zvládnutelné, avšak v prípade trojdimenzionálnych rádiologických simkov to už môže byť problém. Naše vstupné snímky majú po zmenšení rozmer \textit{[104, 128, 104]}, čiže ak aby sme odstraňovali zo snímku po jednom voxeli, museli by sme vykonať \textit{1 384 448} evaluácii pomocou nášho modelu (čo trvá niekoľko hodín, aj pri evaluovaní v maximálnych možných dávkach vzhľadom na pamäť grafickej karty). Preto sme sa rozhodli pridávať po $n$ ($\sim100$) voxeloch v každom kroku. V prípade metódy insertion vkladáme do snímku plného núl (môžeme prípadne aj jednotiek). Keďže kód je rozsiahlejší, uvedieme len pseudokód.

\begin{lstlisting}
method = 'insertion'
step_size = 150 # how many voxels to insert/delete in one evaluation
image_x, image_y = get_image()
image_y_pred = model.predict(image_x)
heatmap = get_heatmap()
voxels = get_ordered_voxels_by_heat(heatmaps)
sequence = get_images_sequence(voxels, step_size) # create a sequence from images where each next image has n inserted/deleted voxels
y_pred = []

for batch_x, batch_y in sequence:
    batch_y_pred = model.predict(batch_x)
    for y in batch_y_pred:
        y_pred.append(y)

auc = metrics.auc([i * step_size for i in range(len(y_pred))], y_pred) / get_voxels_count(image_x)
\end{lstlisting}

\section{Model na detekciu Alzheimerovej choroby na základe MRI snímok}

V tejto sekcii popíšeme impelentáciu modelu, z ktorého predikcií vytvárame tepelné mapy. Náš model - neuónovú sieť sme sa rozdhodli implementovať v knižnici Tensorflow (v2.3.0). Naším cieľom nie je natrénovať najlepší model na dekekciu Alzheimerovej choroby, ale model ktorý je použiteľný na overenie nami narvhnutej metódy. Preto nevykonáme komplexnejšie prístupy k detekcii Alzheimerovej chorby, ktoré sme popísali v analýze (Sekcia \ref{sec:nn_ad_prediction}), ako je napríklad učenie prenosom pomocou autoenkodéra.

\subsection{Dátová sada}

Použili sme dátovú sadu ADNI. Ako vstup modelu je celý MRI snímok (tj. všetky tri dimenzie), nepoužívame žiadné ine údaje z dátovej sady ADNI, ako napríklad demografické údaje a pod. keďže model plánujeme používať iba na vytváranie tepelných máp pre vstupné snímky. 

V dátovej sade sa nachádza celkom 502 MRI snímok, z toho 311 pacientov s Alzheimerovou chorobou (AD) a 191 bez (CN). Dátovú sadu máme teda nevyváženú a model môže začať preferovať jednu triedu. Na zabránenie tomuto javu existuje niekoľko techník, napríklad nadvzorkovanie (angl. oversampling) alebo podvzorkovanie (angl. undersampling) kedy sa doplní synetetickými minoritná trieda, alebo sa odstránia nejaké pozorovania z majoritnej triedy. My sme sa však rozhodli nastaviť predikovaným triedam váhy, ktoré sú zohľadnené v chybovej funkcii, taktiež sme nainicializovali chybu \footnote{\url{https://www.tensorflow.org/tutorials/structured\_data/imbalanced\_data\#optional\_set\_the\_correct\_initial\_bias}} pre neuróny na poslednej vrstve aby reflektovala to, že triedy sú nevyvážené.

Dátovú sadu MRI snímiek pacientov sme náhodným výberom rozdelili na trénovaciu a testovaciu v pomere 80/20. Validačnú sadu sme nevytávarali, z dôvodu malého množstva dát, ktoré máme k dispozícii a taktiež neplánujeme prehladávať priestor hyper parametrov za účelom nájsť ich najoptimálnejšiu kombináciu. Alternatívne by bolo vykonanie krížovej validácie (angl. cross validation) pri trénovaní. Aj po rozdelení sa nám podarilo zachovať pôvodný pomer medzi triedami -- 62/38 (Obr. \ref{fig:dataset_classes}).

\begin{figure}[H]
    \centering
    \includegraphics[width=10cm]{assets/images/dataset_classes.png}
    \caption{Početnosť tried medzi trénovacou a testovacou sadou - je zrejmá prevaha triedy AD.}
    \label{fig:dataset_classes}
\end{figure}

\subsubsection{Predspracovanie}

MRI snímky boli predspracované štandardnou postupnosťou nástroja Freesurfer \footnote{\url{https://surfer.nmr.mgh.harvard.edu/}}, avšak nevykonali sme odstránenie lebky z MRI snímok.

Ďalej sme vykonali:

\begin{itemize}
    \item Upravenie vstupných snímok zmenšením na rovnakú veľkosť 104 x 128 x 104 voxelov. \citeauthor*{esmaeilzadeh2018end} upravili vstupné snímky na veľkosť 116 x 130 x 83, k týmto číslam sme sa pokúsili priblížiť. Pomer veľkostí dimenzií ale nemáme rovnaký, aj z dôvodu, že sme nevykonali odstránenie lebky zo vstupných snímok.
    \item Štandardizáciu vstupných dát (preškálovanie na rozsah $<0, 1>$) nasledovným vzorcom: $\frac{(image\_x - images\_min])}{(images\_max - images\_min)}$.
\end{itemize}

Snímky z dátovej sady sme augmentovali, tak ako sme uviedli v návrhu (Sekcia \ref{sec:design_model}.

\subsection{Model}

Implementujeme neurónové siete na základe návrhu (Sekcia \ref{sec:design_model}).

\paragraph{3D konvolučná neurónová sieť od \citeauthor*{esmaeilzadeh2018end}} Implementovali sme jej jednoduchšiu verziu, ktorá dosahovala lepšie výsledky, opísali sme ju v sekcii \ref{sec:nn_ad_prediction}. Táto neurónová sieť má celkovo \textit{2 899 778} parametrov.

\paragraph{2D ResNet a 3D ResNet} V prípade 2D ResNetu-u používame 2D konvolúcie, tie nám budú fungovať aj napriek tomu, že máme 3D dáta. Vstup do 2D ResNet-u je tiež 3D matica, ktorej tretia dimenzia býva o obvykle o dĺžky 1 alebo 3 (RGB), v našom prípade je o veľkosti poslednej dimenzie snímky. Rozmery vstupných dát pre 2D ResNet sú $[104, 128, 104]$ a pre 3D ResNet $[104, 128, 104, 1]$. Za konvolučné vrstvy a globálnu združovaciu vrstvu sme pripojili dve plne prepojené vrstvy s 512, 256 a 128 neurónami a s aktivačnou funkciou \textit{ReLU}, následne už nasleduje iba posledná vrstva s aktiváciou \textit{softmax}. Tieto neurónové siete majú celkovo \textit{12 689 602}, resp. \textit{34 356 354} parametrov.

% TODO: diagram pre architekturu ResNet18

\subsection{Trénovanie}

Pri trénovaní sme použili:

\begin{itemize}
    \item kategorickú entropiu (angl. categorical crossentropy) ako chybovú funkciu s podporou pre nevyvážené triedy (tj. táto funkcia brala ohľad na váhy tried, ktoré sme nastavili nepriamo úmerne ich veľkosti),
    \item optimalizačný algoritmus Adam s prevolenými nastaveniami,
    \item exponenciálne tlmenie rýchlosti učenia (angl. learning rate decay), s hodnotou $0,96$ každých 25 epoch,
    \item skoré zastavenie trénovania ak sa metrika AUC (plocha pod krivkou) nezlepšila za posledných 50 epoch,
    \item veľkosť dávky (angl. batch size) -- 10 (vždy tak, aby sme naplno využili pamäť grafickej karty),
    \item $l2$ regularizáciu (rovnako ako \citeauthor*{esmaeilzadeh2018end}).
\end{itemize}

Trénovanie sme začali s modelom bez augmentácii, dávkovej normalizácie, dropoutu a regularizácie pričom sme ich postupne pridávali, dolaďovali a sledovali zmeny v úspešnosti modelu. Najlepšie výsledky sme dosiahli s architektúrou 3D ResNet s presnosťou 80\% (Tabuľka \ref{tab:model_training_results}). Nepodarilo sa nám nám teda priblížiť k výsledkom analyzovaných prác, čo však v konečnom dôsledku ani nie je cieľom tejto práce.

% \begin{landscape}
\begin{table}[H]
    \centering
    \begin{tabular}{|
    >{\columncolor[HTML]{EFEFEF}}c |c|r|r|r|r|r|}
    \hline
    \multicolumn{2}{|l|}{\cellcolor[HTML]{C0C0C0}} &
        \multicolumn{1}{l|}{\footnotesize{Baseline}} &
        \multicolumn{1}{l|}{\begin{tabular}[c]{@{}c@{}}\footnotesize{+ Augmen-}\\ \footnotesize{tácie}\end{tabular}} &
        \multicolumn{1}{l|}{\begin{tabular}[c]{@{}c@{}}\footnotesize{+ Dávko-}\\ \footnotesize{vá norma-}\\ \footnotesize{lizácia}\end{tabular}} &
        \multicolumn{1}{l|}{\footnotesize{+ Dropout}} &
        \multicolumn{1}{l|}{\begin{tabular}[c]{@{}c@{}}\footnotesize{+ Regula-}\\ \footnotesize{rizácia (l2)}\end{tabular}} \\ \hline
        \cellcolor[HTML]{EFEFEF}                                                                      & Acc.  & 0.71 & 0.67 & 0.75 & 0.75 & 0.71 \\ \cline{2-7} 
        \cellcolor[HTML]{EFEFEF}                                                                      & Sens. & 0.76 & 0.68 & 0.77 & 0.76 & 0.70 \\ \cline{2-7} 
        \multirow{-3}{*}{\cellcolor[HTML]{EFEFEF}\begin{tabular}[c]{@{}c@{}}3D\\ CNN\end{tabular}}    & Spec. & 0.63 & 0.66 & 0.71 & 0.74 & 0.71 \\ \hline
        \cellcolor[HTML]{EFEFEF}                                                                      & Acc.  & 0.71 & 0.69 & 0.80 & 0.74 & 0.79 \\ \cline{2-7} 
        \cellcolor[HTML]{EFEFEF}                                                                      & Sens. & 0.79 & 0.84 & 0.85 & 0.94 & 0.87 \\ \cline{2-7} 
        \multirow{-3}{*}{\cellcolor[HTML]{EFEFEF}\begin{tabular}[c]{@{}c@{}}3D\\ ResNet\end{tabular}} & Spec. & 0.57 & 0.45 & 0.71 & 0.42 & 0.66 \\ \hline
        \cellcolor[HTML]{EFEFEF}                                                                      & Acc.  & 0.67 & 0.76 & 0.77 & 0.77 & 0.78 \\ \cline{2-7} 
        \cellcolor[HTML]{EFEFEF}                                                                      & Sens. & 0.77 & 0.90 & 0.89 & 0.85 & 0.89 \\ \cline{2-7} 
        \multirow{-3}{*}{\cellcolor[HTML]{EFEFEF}\begin{tabular}[c]{@{}c@{}}2D\\ ResNet\end{tabular}} & Spec  & 0.50 & 0.52 & 0.58 & 0.63 & 0.61 \\ \hline
    \end{tabular}
    \caption{\textbf{Výsledky trénovania.} Acc. = presnosť (angl. Accouracy), Sens. = senzitivita (angl. Sensitivity), Spec. = Špecificita (angl. Specificity)}
        \label{tab:model_training_results}
\end{table}
% \end{landscape}

Oproti \citeauthor*{esmaeilzadeh2018end}, ktorí dosiahli presnosť až 94\%, sme dosiahli presnosť len 72\% avšak sme mali menej dát (o 339 pozorovaní menej), neodstraňovali sme zo snímok lebku a nepoužili sme pri klasifikácii vek pacienta. Avšak robili sme viac augmentácií, no po ich pridaní sa úspešnosť modelu zhoršila (Obr. \ref{fig:3d_cnn_training}) (ale následne sa už iba zlepšovala), je teda možné, že niektoré augmentácie sú nekorektné a deštruktívne voči vstupným snímkam a vedú k zhoršeniu výkonnosti modelu. Aj po pridaní veľmi slabej regularizácie, sa úspešnosť modelu zhoršila. V prípade 2D a 3D ResNet architektúr sa nám podarilo dosiahnuť lepšie výsledky, avšak v ich prípade sa sieť neskôr začala pretrénovávať (Obr. \ref{fig:2d_3d_res_net_training}
) aj napriek použitej regularizácii, čo môže naznačovať, že sú tieto architektúry na náš problém príliš komplexné.

Identifikovali sme nasledovné možné vylepšenia (zoradené podľa subjektívneho pomeru úsilie/vplyv):
\begin{itemize}
    \item Porovnať jednotlivé augmentácie a vyhodiť tie deštruktívne.
    \item Odstránenie lebky zo snímok.
    \item Nájsť a použiť viac dát.
    \item Krížová validácia v prípade väčšieho nastavovania hyperparametrov.
    \item Učenie prenosom pomocou autoenkodéra \cite{hosseini2016alzheimer}.
\end{itemize}

Vzhľadom na to, že naším cieľom nie je natrénovať najlepšiu neurónovú sieť, nevykonali sme všetky identifikované možné vylepšenia. Vykonali sme porovnanie jednotlivých augmenácií na architektúre 3D CNN a to tak, že sme pre každú augemtáciu natrénovali samostatný model (bez dropout-u a regularizácie) a augmentovali sme vstupné snímky s pravdepodobnosťou 50\%. Sledovali sme, či sa aj s augemntovanými snímkami netrénované modely bez akejkoľvek regularizácie dokážu preučiť. Model sa nepreučil iba pri augmentácii \textit{náhodné priblíženie}. Následne sme natrénovali modely pre jednotlivé architektúry znovu, lepší model sa nám podarilo natrénovať iba pre architektúru 3D CNN, presnosť - \textbf{0.78}, senzitivita - \textbf{0.81}, špecificita - \textbf{0.74}.

\begin{figure}[H]
    \centering
    \includegraphics[width=14cm]{assets/images/3d_cnn_training.png}
    \caption{Priebeh trénovania 3D konvolučnej neurónovej siete, čím viac sme pridali regularizácie (l2 alebo dropout) tým sme dosiahli horšie výsledky. Po pridaní augmentácií sa úspešnosť modelu zhoršila, avšak následne sa už iba zlepšovala.}
    \label{fig:3d_cnn_training}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=12cm]{assets/images/2d_3d_res_net_training.png}
    \caption{Priebeh trénovania 2D a 3D ResNet neurónovej siete. V oboch prípadoch sme použili dropout aj regularizáciu. Od približne 30-tej epochy sa neurónová sieť začala pretrénovávať, aj napriek regularizácii. Ako vylepšenie je možné skúsiť silnesjšiu regularizáciu (väčšiu hodnotu l2 a dropout), ak ani to nepomôže, je možné, že architektúra je príliš komplexná náš problém (neurónová sieť je príliš hlboká). Môžeme ďalej skúsiť odstrániť jednu plne prepojenú vrstvu alebo znížiť počet neurónov v týchto vrstvách.}
    \label{fig:2d_3d_res_net_training}
\end{figure}

\section{Zhrnutie}

V tejto kapitole sme opísali, ako sme implementovali nami navrhovanú metódu a spôsob jej overenie. Opísali sme implemetáciu kľúčových prvkov (generovanie masiek a vytvorenie tepelnej mapy) navrhovanej metódy RISEI a jej hyper parametre. Rovnako sme opísali aj implementáciu neurónovej siete, architektúru, spôsob trénovania a použitú dátovú sadu. Metódu RISEI sa nám podarilo implementovať a je ju možné použiť v experimentoch. Podarilo sa nám natrénovať niekoľko architektúr neurónových sietí, pričom sme indetifikovali možné príčiny výsledkov, ktoré dosahujú (a navrhli spôsob ako ich riešiť). Nie všetky identifikované príčiny sa nám podarilo vyriešiť, keďže cieľom tejto práce nie je natrénovať najlepší model, ale natrénovať taký model, ktorý je postačujúci na overenie navrhnutej metódy.
