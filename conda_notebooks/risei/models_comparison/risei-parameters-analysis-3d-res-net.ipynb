{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "searching-lecture",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "demonstrated-secret",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../..')\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from src.data import train_test_split, MRISequence\n",
    "from src.model import create_model, compile_model, load_checkpoint\n",
    "from src.model.evaluation import show_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "differential-highlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['image.cmap'] = 'viridis'\n",
    "\n",
    "%config InlineBackend.figure_format='retina'\n",
    "plt.rcParams.update({'font.size': 15})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "atlantic-ethernet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.2\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# RANDOM_SEED = 250398\n",
    "# tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "print(tf.version.VERSION)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qualified-cricket",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "wicked-characterization",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not copying files since the destination directory already exists\n",
      "initializing train_seq...\n",
      "initializing test_seq...\n",
      "val_seq = test_seq\n",
      "log_dir: ../../../tmp\\logs\\20210504-190329\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ROOT_DIR = '../../../tmp'\n",
    "DEFAULT_CHECKPOINT_DIRECTORY_LOCAL = os.path.join(ROOT_DIR, 'checkpoints')\n",
    "DEFAULT_BCKP_CHECKPOINT_DIRECTORY_LOCAL = os.path.join(ROOT_DIR, 'bckp-checkpoints')\n",
    "\n",
    "LOG_DIRECTORY = os.path.join(ROOT_DIR, 'logs')\n",
    "CHECKPOINT_DIRECTORY = DEFAULT_CHECKPOINT_DIRECTORY_LOCAL\n",
    "\n",
    "LOG_DIRECTORY_LOCAL = LOG_DIRECTORY\n",
    "CHECKPOINT_DIRECTORY_LOCAL = CHECKPOINT_DIRECTORY\n",
    "\n",
    "DATA_DIR_NAME = 'data-v3'\n",
    "DATA_DIR = os.path.join(ROOT_DIR, DATA_DIR_NAME)\n",
    "\n",
    "saliencies_and_segmentations_v2_path = os.path.join(ROOT_DIR, 'saliencies_and_segmentations_v2')\n",
    "\n",
    "if not os.path.exists(CHECKPOINT_DIRECTORY):\n",
    "    os.mkdir(CHECKPOINT_DIRECTORY)\n",
    "\n",
    "if not os.path.exists(LOG_DIRECTORY):\n",
    "    os.mkdir(LOG_DIRECTORY)\n",
    "\n",
    "val = False\n",
    "\n",
    "class_names = ['AD', 'CN']\n",
    "\n",
    "# get paths to data\n",
    "train_dir, test_dir, val_dir = train_test_split(\n",
    "    saliencies_and_segmentations_v2_path,\n",
    "    ROOT_DIR,\n",
    "    split=(0.8, 0.15, 0.05),\n",
    "    dirname=DATA_DIR_NAME)\n",
    "\n",
    "# set the batch size for mri seq\n",
    "batch_size = 12\n",
    "input_shape = (104, 128, 104, 1) # (112, 112, 105, 1)\n",
    "resize_img = True\n",
    "crop_img = True\n",
    "\n",
    "# if y is one-hot encoded or just scalar number\n",
    "one_hot = True\n",
    "\n",
    "# class weightss (see analysis notebook)\n",
    "class_weights = {0: 0.8072289156626505, 1: 1.3137254901960784}\n",
    "\n",
    "# description statistics of the dataset\n",
    "desc = {'mean': -3.6344006e-09, 'std': 1.0000092, 'min': -1.4982183, 'max': 10.744175}\n",
    "\n",
    "if 'desc' not in locals():\n",
    "    print('initializing desc...')\n",
    "    desc = get_description(MRISequence(\n",
    "        train_dir,\n",
    "        64,\n",
    "        class_names=class_names,\n",
    "        input_shape=input_shape),\n",
    "        max_samples=None)\n",
    "    print(desc)\n",
    "\n",
    "\n",
    "normalization={ 'type':'normalization', 'desc': desc }\n",
    "# normalization={'type':'standardization', 'desc':desc }\n",
    "\n",
    "augmentations = None\n",
    "augmentations_inplace = True\n",
    "# enable augmentations in mri seq (otherwise it can be enabled in dataset)\n",
    "# augmentations={ 'random_swap_hemispheres': 0.5 }\n",
    "\n",
    "# initialize sequences\n",
    "print('initializing train_seq...')\n",
    "train_seq = MRISequence(\n",
    "    train_dir,\n",
    "    batch_size,\n",
    "    class_names=class_names,\n",
    "    augmentations=augmentations,\n",
    "    augmentations_inplace=augmentations_inplace,\n",
    "    input_shape=input_shape,\n",
    "    resize_img=resize_img,\n",
    "    crop_img=crop_img,\n",
    "    one_hot=one_hot,\n",
    "    class_weights=class_weights,\n",
    "    normalization=normalization)\n",
    "\n",
    "print('initializing test_seq...')\n",
    "test_seq = MRISequence(\n",
    "    test_dir,\n",
    "    batch_size,\n",
    "    class_names=class_names,\n",
    "    input_shape=input_shape,\n",
    "    resize_img=resize_img,\n",
    "    crop_img=crop_img,\n",
    "    one_hot=one_hot,\n",
    "    normalization=normalization)\n",
    "\n",
    "if val:\n",
    "    print('initializing val_seq...')\n",
    "    val_seq = MRISequence(\n",
    "        val_dir,\n",
    "        batch_size,\n",
    "        class_names=class_names,\n",
    "        input_shape=input_shape,\n",
    "        resize_img=resize_img,\n",
    "        crop_img=crop_img,\n",
    "        one_hot=one_hot,\n",
    "        class_weights=class_weights,\n",
    "        normalization=normalization)\n",
    "else:\n",
    "    print('val_seq = test_seq')\n",
    "    val_seq = test_seq\n",
    "\n",
    "model_key = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "log_dir = os.path.join(LOG_DIRECTORY, model_key)\n",
    "print(f'log_dir: {log_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-knowing",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Each experiment consisted of 10 images, 5 TP and 5 TN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apparent-advertiser",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "fpath = os.path.join(ROOT_DIR, \"risei-history/risei-3d-res-net-parameters\")\n",
    "\n",
    "files = [f for f in listdir(fpath) if isfile(join(fpath, f))]\n",
    "files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-microphone",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def parse(fname):\n",
    "    p = re.compile(\"^hmap-parameters--(\\w+)--b1\\+(\\d+[.]?\\d*)-b2\\+(\\d+[.]?\\d*)-b2\\+(\\d+[.]?\\d*)\\.cls$\")\n",
    "    return p.match(fname).groups()\n",
    "\n",
    "print(parse('hmap-parameters--deletion--b1+0-b2+0.5-b2+0.cls'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-intervention",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.heatmaps.evaluation import HeatmapEvaluationHistory\n",
    "\n",
    "data = {}\n",
    "\n",
    "\n",
    "def append(key, value):\n",
    "    if not key in data:\n",
    "        data[key] = []\n",
    "    data[key].append(value)\n",
    "\n",
    "    \n",
    "for fname in files:\n",
    "    metric, b1, b2, b2_value = parse(fname)\n",
    "    append('metric', metric)\n",
    "    append('b1', float(b1))\n",
    "    append('b2', float(b2))\n",
    "    append('b2_value', float(b2_value))\n",
    "    \n",
    "#     print(f\"loading {fname}...\")\n",
    "    history = HeatmapEvaluationHistory.load(fpath, fname[:-4])\n",
    "    desc = history._description()\n",
    "    for key, value in desc.items():\n",
    "        append(key, value)\n",
    "    \n",
    "    \n",
    "df = pd.DataFrame(data=data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-placement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def table(metric, value):\n",
    "    df_m = df[df['metric'] == metric]\n",
    "    return pd.pivot_table(df_m, values=value, index=[\"b1\"], columns=[\"b2\", \"b2_value\"], fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-allergy",
   "metadata": {},
   "outputs": [],
   "source": [
    "table('deletion', 'auc_median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-kennedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "table('insertion', 'auc_median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "major-machinery",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m = df.copy().sort_values(\"b1\")\n",
    "pd.pivot_table(df_m, values=\"auc_median\", index=[\"b1\"], columns=[\"metric\", \"b2\", \"b2_value\"], fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-pointer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m = df.copy().sort_values(\"b1\")\n",
    "pd.pivot_table(df_m, values=\"auc_median\", index=[\"b1\"], columns=[\"metric\", \"b2\", \"b2_value\"], fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-budapest",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'auc_median'\n",
    "df_m = df.copy().sort_values('b1')\n",
    "def apply_fn(row):\n",
    "    if row['metric'] == 'deletion':\n",
    "        return 1 - row[col]\n",
    "    return row[col]\n",
    "df_m[col] = df.apply(apply_fn, axis=1)\n",
    "\n",
    "pd.pivot_table(df_m, values=col, index=['b1'], columns=['b2', 'b2_value'], fill_value=np.nan)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
