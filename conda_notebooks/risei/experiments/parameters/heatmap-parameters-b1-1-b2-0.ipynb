{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RISEI Parameters Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../../..')\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from src.data import train_test_split, MRISequence\n",
    "from src.model import create_model, compile_model, load_checkpoint\n",
    "from src.model.evaluation import show_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['image.cmap'] = 'viridis'\n",
    "\n",
    "%config InlineBackend.figure_format='retina'\n",
    "plt.rcParams.update({'font.size': 15})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# RANDOM_SEED = 250398\n",
    "# tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "print(tf.version.VERSION)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ROOT_DIR = '../../../../tmp'\n",
    "DEFAULT_CHECKPOINT_DIRECTORY_LOCAL = os.path.join(ROOT_DIR, 'checkpoints')\n",
    "DEFAULT_BCKP_CHECKPOINT_DIRECTORY_LOCAL = os.path.join(ROOT_DIR, 'bckp-checkpoints')\n",
    "\n",
    "LOG_DIRECTORY = os.path.join(ROOT_DIR, 'logs')\n",
    "CHECKPOINT_DIRECTORY = DEFAULT_CHECKPOINT_DIRECTORY_LOCAL\n",
    "\n",
    "LOG_DIRECTORY_LOCAL = LOG_DIRECTORY\n",
    "CHECKPOINT_DIRECTORY_LOCAL = CHECKPOINT_DIRECTORY\n",
    "\n",
    "DATA_DIR_NAME = 'data-v3'\n",
    "DATA_DIR = os.path.join(ROOT_DIR, DATA_DIR_NAME)\n",
    "\n",
    "saliencies_and_segmentations_v2_path = os.path.join(ROOT_DIR, 'saliencies_and_segmentations_v2')\n",
    "\n",
    "if not os.path.exists(CHECKPOINT_DIRECTORY):\n",
    "    os.mkdir(CHECKPOINT_DIRECTORY)\n",
    "\n",
    "if not os.path.exists(LOG_DIRECTORY):\n",
    "    os.mkdir(LOG_DIRECTORY)\n",
    "\n",
    "val = False\n",
    "\n",
    "class_names = ['AD', 'CN']\n",
    "\n",
    "# get paths to data\n",
    "train_dir, test_dir, val_dir = train_test_split(\n",
    "    saliencies_and_segmentations_v2_path,\n",
    "    ROOT_DIR,\n",
    "    split=(0.8, 0.15, 0.05),\n",
    "    dirname=DATA_DIR_NAME)\n",
    "\n",
    "# set the batch size for mri seq\n",
    "batch_size = 12\n",
    "input_shape = (104, 128, 104, 1) # (112, 112, 105, 1)\n",
    "resize_img = True\n",
    "crop_img = True\n",
    "\n",
    "# if y is one-hot encoded or just scalar number\n",
    "one_hot = True\n",
    "\n",
    "# class weightss (see analysis notebook)\n",
    "class_weights = {0: 0.8072289156626505, 1: 1.3137254901960784}\n",
    "\n",
    "# description statistics of the dataset\n",
    "desc = {'mean': -3.6344006e-09, 'std': 1.0000092, 'min': -1.4982183, 'max': 10.744175}\n",
    "\n",
    "if 'desc' not in locals():\n",
    "    print('initializing desc...')\n",
    "    desc = get_description(MRISequence(\n",
    "        train_dir,\n",
    "        64,\n",
    "        class_names=class_names,\n",
    "        input_shape=input_shape),\n",
    "        max_samples=None)\n",
    "    print(desc)\n",
    "\n",
    "\n",
    "normalization={ 'type':'normalization', 'desc': desc }\n",
    "# normalization={'type':'standardization', 'desc':desc }\n",
    "\n",
    "augmentations = None\n",
    "augmentations_inplace = True\n",
    "# enable augmentations in mri seq (otherwise it can be enabled in dataset)\n",
    "# augmentations={ 'random_swap_hemispheres': 0.5 }\n",
    "\n",
    "# initialize sequences\n",
    "print('initializing train_seq...')\n",
    "train_seq = MRISequence(\n",
    "    train_dir,\n",
    "    batch_size,\n",
    "    class_names=class_names,\n",
    "    augmentations=augmentations,\n",
    "    augmentations_inplace=augmentations_inplace,\n",
    "    input_shape=input_shape,\n",
    "    resize_img=resize_img,\n",
    "    crop_img=crop_img,\n",
    "    one_hot=one_hot,\n",
    "    class_weights=class_weights,\n",
    "    normalization=normalization)\n",
    "\n",
    "print('initializing test_seq...')\n",
    "test_seq = MRISequence(\n",
    "    test_dir,\n",
    "    batch_size,\n",
    "    class_names=class_names,\n",
    "    input_shape=input_shape,\n",
    "    resize_img=resize_img,\n",
    "    crop_img=crop_img,\n",
    "    one_hot=one_hot,\n",
    "    normalization=normalization)\n",
    "\n",
    "if val:\n",
    "    print('initializing val_seq...')\n",
    "    val_seq = MRISequence(\n",
    "        val_dir,\n",
    "        batch_size,\n",
    "        class_names=class_names,\n",
    "        input_shape=input_shape,\n",
    "        resize_img=resize_img,\n",
    "        crop_img=crop_img,\n",
    "        one_hot=one_hot,\n",
    "        class_weights=class_weights,\n",
    "        normalization=normalization)\n",
    "else:\n",
    "    print('val_seq = test_seq')\n",
    "    val_seq = test_seq\n",
    "\n",
    "model_key = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "log_dir = os.path.join(LOG_DIRECTORY, model_key)\n",
    "print(f'log_dir: {log_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#class_weights\n",
    "# pos / neg\n",
    "initial_bias = np.log([159/243, 243/159])\n",
    "\n",
    "model_type = '3d_cnn'\n",
    "model_config = {\n",
    "    'input_shape': input_shape,\n",
    "    'class_names': class_names,\n",
    "#     'l2_beta': 0.001,\n",
    "#     'l2_beta': 0.0005,\n",
    "    'l2_beta': None,\n",
    "#     'dropout': 0.05,\n",
    "    'dropout': 0.10,\n",
    "    'output_bias': initial_bias,\n",
    "#     'output_bias': None,\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization\n",
    "    'batch_norm': True,\n",
    "    'is_complex': False, # a complex layer from the paper, max batch_size is 3\n",
    "}\n",
    "\n",
    "compile_config = {\n",
    "    # default is 0.001\n",
    "#     'learning_rate': 0.000075,\n",
    "    'learning_rate': 0.00010,\n",
    "    'decay_steps': 25,\n",
    "    'decay_rate': 0.96,\n",
    "#     'beta_1': 0.85,\n",
    "    'beta_1': 0.90,\n",
    "#     'beta_2': 0.990,\n",
    "    'beta_2': 0.999,\n",
    "}\n",
    "\n",
    "train_config = {\n",
    "    'model_key': model_key,\n",
    "    'epochs': 150,\n",
    "    'patience': 75,\n",
    "    'tensorboard_update_freq': 'epoch',\n",
    "    'mri_tensorboard_callback': False,\n",
    "    'model_checkpoint_callback': {'monitor': 'val_auc', 'mode': 'max', 'save_best_only': True},\n",
    "    'early_stopping_monitor': {'monitor': 'val_auc', 'mode': 'max'},\n",
    "#     'augmentations': False,\n",
    "    'augmentations': {\n",
    "        'invert': (0.5, None),\n",
    "        'rotate': (0.2, 5), # probability, degrees\n",
    "        'zoom': (0., 0.),\n",
    "        'shear': (0.2, 0.5), # probability, degrees\n",
    "        'blur': (0.2, 0.85),\n",
    "        'noise': (0.2, 0.00020)\n",
    "    },\n",
    "    'batch_size': 8,\n",
    "#     'model_checkpoint_callback': False,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = create_model(model_type, model_config)\n",
    "model, *_ = compile_model(model, **compile_config)\n",
    "model.build(input_shape=input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "load_checkpoint(model, DEFAULT_BCKP_CHECKPOINT_DIRECTORY_LOCAL, '20210308-175324', 'cp-0058.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# just to test of it is ok to clear the session after loading the weigths\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "show_metrics(model, test_seq, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from src.heatmaps.evaluation import get_heatmap\n",
    "from src.risei import RISEI\n",
    "from src.data import tf_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import select_from_dataset, numpy_to_sequence\n",
    "\n",
    "BATCH_SIZE = 24\n",
    "images_x, images_y, images_y_pred = select_from_dataset(tf_predict(model), test_seq, max_category=5, fn_max=0, fp_max=0)\n",
    "print(images_x.shape)\n",
    "sequence = numpy_to_sequence(images_x, images_y, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 24\n",
    "VERBOSE = 1\n",
    "LOG = True\n",
    "SEED = 42\n",
    "RISEI_BATCH_SIZE = 480\n",
    "\n",
    "heatmap_evaluation_options = {\n",
    "    'evaluation_step_size': 1000,\n",
    "    'evaluation_max_steps': -1,\n",
    "    'evaluation_batch_size': BATCH_SIZE\n",
    "}\n",
    "\n",
    "# risei config\n",
    "risei_config = {\n",
    "    's': 8, \n",
    "    'p1': 1/3, \n",
    "    'b1': 1,\n",
    "    'b2': 0,\n",
    "    'b2_value': 0,\n",
    "    'in_paint': '2d', \n",
    "    'in_paint_blending': True, \n",
    "    'in_paint_radius': 5,\n",
    "    'in_paint_2d_to_3d': True,\n",
    "    'processes': 8,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "p1_options = [1/4, 1/3, 1/2, 2/3, 3/4]\n",
    "masks_counts = [8, 16, 32, 64, 128, 256, 512, 1024, 2048]\n",
    "masks_counts = [1024, 2048]\n",
    "\n",
    "def map_fn(config, value):\n",
    "    config.update({ 'p1': value })\n",
    "    return config\n",
    "\n",
    "experiments = itertools.product(masks_counts, p1_options)\n",
    "# m - masks_count\n",
    "# p1 - p1 in rise config\n",
    "experiments = [(masks_count, f\"m+{masks_count}-p1+{value}\", map_fn(risei_config.copy(), value)) \n",
    "               for masks_count, value in experiments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.heatmaps.evaluation import HeatmapEvaluationV2\n",
    "from src.heatmaps.heatmaps import get_heatmap\n",
    "from src.data import tf_predict, torch_predict\n",
    "from src.risei import RISEI\n",
    "\n",
    "\n",
    "def get_heatmap_fn(risei, masks_count):\n",
    "    def heatmap_fn(image_x, image_y, **kwargs): # kwargs - log, seed, evaluation_idx\n",
    "        seed = kwargs.get('seed', None)\n",
    "        evaluation_idx = kwargs.get('evaluation_idx', None)\n",
    "        log = kwargs.get('log', None)\n",
    "        heatmap_seed = None if seed is None else seed + evaluation_idx\n",
    "        print(f\"generating heatmap (masks_count={masks_count}; seed={heatmap_seed})\")\n",
    "        heatmap, _, _ = get_heatmap(\n",
    "            image_x,\n",
    "            image_y,\n",
    "            model,\n",
    "            risei,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            masks_count=masks_count,\n",
    "            risei_batch_size=RISEI_BATCH_SIZE,\n",
    "            debug=False,\n",
    "            seed=heatmap_seed,\n",
    "            log=log\n",
    "        )\n",
    "        # print(f'{image_x.shape} {heatmap.shape}')\n",
    "        return heatmap.reshape(input_shape)\n",
    "    return heatmap_fn\n",
    "\n",
    "predict_fn = tf_predict(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(experiments):\n",
    "    for masks_count, history_fname, risei_config in experiments:\n",
    "        print(f'\\n*********\\nrunning experiment: {history_fname}\\n---------\\n')\n",
    "        risei = RISEI(input_shape[:-1], debug=False, **risei_config)\n",
    "        heatmap_fn = get_heatmap_fn(risei, masks_count)\n",
    "        he = HeatmapEvaluationV2(predict_fn, heatmap_fn, sequence, **heatmap_evaluation_options)\n",
    "        \n",
    "        for method in ['insertion', 'deletion']:\n",
    "            print('\\n')\n",
    "            history = he.evaluate(method, log=LOG, verbose=VERBOSE, seed=SEED)\n",
    "            history.save(os.path.join(ROOT_DIR, 'risei-history/hmap-parameters'), f'hmap-parameters--{method}--{history_fname}')\n",
    "        \n",
    "        tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'number of experiments: {len(experiments) * 2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "run(experiments[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "run(experiments[10:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "run(experiments[30:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "run(experiments[40:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
