{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'simpleitk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1ed2fb64715b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msimpleitk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_path_to_saliencies_and_segmentations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMRISequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'simpleitk'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from src.data import train_test_split, get_path_to_saliencies_and_segmentations, MRISequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ROOT_DIR = '../../tmp'\n",
    "DEFAULT_CHECKPOINT_DIRECTORY_LOCAL = os.path.join(ROOT_DIR, 'checkpoints')\n",
    "DEFAULT_BCKP_CHECKPOINT_DIRECTORY_LOCAL = os.path.join(ROOT_DIR, 'bckp-checkpoints')\n",
    "\n",
    "LOG_DIRECTORY = os.path.join(ROOT_DIR, 'logs')\n",
    "CHECKPOINT_DIRECTORY = DEFAULT_CHECKPOINT_DIRECTORY_LOCAL\n",
    "\n",
    "LOG_DIRECTORY_LOCAL = LOG_DIRECTORY\n",
    "CHECKPOINT_DIRECTORY_LOCAL = CHECKPOINT_DIRECTORY\n",
    "\n",
    "saliencies_and_segmentations_v2_path = get_path_to_saliencies_and_segmentations(ROOT_DIR)\n",
    "\n",
    "if not os.path.exists(CHECKPOINT_DIRECTORY):\n",
    "    os.mkdir(CHECKPOINT_DIRECTORY)\n",
    "\n",
    "if not os.path.exists(LOG_DIRECTORY):\n",
    "    os.mkdir(LOG_DIRECTORY)\n",
    "\n",
    "class_names = ['AD', 'CN']\n",
    "\n",
    "# get paths to data\n",
    "train_dir, test_dir, val_dir = train_test_split(\n",
    "    saliencies_and_segmentations_v2_path, \n",
    "    ROOT_DIR, \n",
    "    split=(0.8, 0.15, 0.05), \n",
    "    dirname='data-v2')\n",
    "\n",
    "# set the batch size for mri seq\n",
    "batch_size = 12\n",
    "input_shape = (112, 112, 105, 1)\n",
    "resize_img = True\n",
    "\n",
    "# if y is one-hot encoded or just scalar number\n",
    "one_hot = True\n",
    "\n",
    "# class weights (see analysis notebook)\n",
    "class_weight = {0: 0.8271604938271606, 1: 1.2641509433962266}\n",
    "\n",
    "# description statistics of the dataset\n",
    "desc = {'mean': -3.6344006e-09, 'std': 1.0000092, 'min': -1.4982183, 'max': 10.744175}\n",
    "\n",
    "if 'desc' not in locals():\n",
    "    print('initializing desc...')\n",
    "    desc = get_description(MRISequence(\n",
    "        train_dir,\n",
    "        64,\n",
    "        class_names=class_names,\n",
    "        input_shape=input_shape),\n",
    "        max_samples=None)\n",
    "    print(desc)\n",
    "\n",
    "\n",
    "normalization={ 'type':'normalization', 'desc': desc }\n",
    "# normalization={'type':'standardization', 'desc':desc }\n",
    "\n",
    "augmentations = None\n",
    "# enable augmentations in mri seq (otherwise it can be enabled in dataset)\n",
    "# augmentations={ 'random_swap_hemispheres': 0.5 }\n",
    "\n",
    "# initialize sequences\n",
    "print('initializing train_seq...')\n",
    "train_seq = MRISequence(\n",
    "    train_dir,\n",
    "    batch_size,\n",
    "    class_names=class_names,\n",
    "    augmentations=augmentations,\n",
    "    augmentations_inplace=not USE_TPU,\n",
    "    input_shape=input_shape,\n",
    "    resize_img=resize_img,\n",
    "    one_hot=one_hot,\n",
    "    class_weight=class_weight,\n",
    "    normalization=normalization)\n",
    "print('initializing val_seq...')\n",
    "val_seq = MRISequence(\n",
    "    val_dir,\n",
    "    batch_size,\n",
    "    class_names=class_names,\n",
    "    input_shape=input_shape,\n",
    "    resize_img=resize_img,\n",
    "    one_hot=one_hot,\n",
    "    class_weight=class_weight,\n",
    "    normalization=normalization)\n",
    "print('initializing test_seq...')\n",
    "test_seq = MRISequence(\n",
    "    test_dir,\n",
    "    batch_size,\n",
    "    class_names=class_names,\n",
    "    input_shape=input_shape,\n",
    "    resize_img=resize_img,\n",
    "    one_hot=one_hot,\n",
    "    normalization=normalization)\n",
    "\n",
    "model_key = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "log_dir = os.path.join(LOG_DIRECTORY, model_key)\n",
    "print(f'log_dir: {log_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#class_weights\n",
    "# pos / neg\n",
    "initial_bias = np.log([243/159, 159/243])\n",
    "\n",
    "model_config = {\n",
    "    'input_shape': input_shape,\n",
    "    'log_dir': log_dir, \n",
    "    'train_seq': train_seq,\n",
    "    'class_names': class_names,\n",
    "#     'l2_beta': 0.001,\n",
    "    'l2_beta': 0.0005,\n",
    "#     'l2_beta': None,\n",
    "    'dropout': 0.10,\n",
    "#     'dropout': None,\n",
    "    'output_bias': initial_bias,\n",
    "#     'output_bias': None,\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization\n",
    "    'batch_norm': False,\n",
    "    'is_complex': False, # a complex layer from the paper, max batch_size is 3\n",
    "}\n",
    "\n",
    "compile_config = {\n",
    "    # default is 0.001\n",
    "#     'learning_rate': 0.000075,\n",
    "    'learning_rate': 0.00025,\n",
    "    'decay_steps': 25,\n",
    "    'decay_rate': 0.96,\n",
    "#     'beta_1': 0.85,\n",
    "    'beta_1': 0.90,\n",
    "#     'beta_2': 0.990,\n",
    "    'beta_2': 0.999,\n",
    "}\n",
    "\n",
    "train_config = {\n",
    "    'tpu': USE_TPU,\n",
    "    'model_key': model_key,\n",
    "    'validation': 'val_test',\n",
    "    'epochs': 150,\n",
    "    'patience': 150,\n",
    "    'tensorboard_update_freq': 'epoch', \n",
    "    'mri_tensorboard_callback': not USE_TPU,\n",
    "    'model_checkpoint_callback': 'save_best_only',\n",
    "#     'model_checkpoint_callback': False,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(**model_config)\n",
    "model, *_ = compile_model(model, **compile_config)\n",
    "model.build(input_shape=input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_checkopint(model, DEFAULT_LOCAL_CHECKPOINT_DIRECTORY, '20201125-180540', 'cp-0085.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model, checkpoint_dir, history = train(\n",
    "    model,\n",
    "    train_seq,\n",
    "    val_seq,\n",
    "    **train_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "show_simple_metrics(model, test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "show_metrics(model, test_seq)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
