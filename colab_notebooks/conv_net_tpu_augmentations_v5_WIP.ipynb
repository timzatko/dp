{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"conv_net_tpu_augmentations_v5_WIP.ipynb","provenance":[{"file_id":"1jIbHT01ngjLe0HQqMT0kiEmdp2E5z_kp","timestamp":1606222548123},{"file_id":"1jdvzanmm6-AjaOp2vp_IX8FL79F9EzHx","timestamp":1606220125985}],"collapsed_sections":["q82dBizXvjha","lwfvJdjQ2yb9"],"toc_visible":true,"machine_shape":"hm","authorship_tag":"ABX9TyMDIqLXIzTggV2VE+7KJdGG"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Qbyhv2Uk8T_B"},"source":["# 3D CNN"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G1SZbMDlAOvG","executionInfo":{"status":"ok","timestamp":1606430401691,"user_tz":-60,"elapsed":847,"user":{"displayName":"Timotej Zaťko","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhG6XJr8UII31SY9awxZmVH0eKaIexl4APNicrOPQ=s64","userId":"16930105438254357424"}},"outputId":"53405a63-5bf4-4cf4-b89a-21daccc599f1"},"source":["import time\n","\n","# wether to use tpu for training or not\n","USE_TPU = False\n","TRAIN_MODEL = True\n","# RANDOM_SEED = 4200\n","RANDOM_SEED = time.time()\n","print(RANDOM_SEED)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1606430401.2708557\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GC5kwWVr8Wvc","executionInfo":{"status":"ok","timestamp":1606430402818,"user_tz":-60,"elapsed":1947,"user":{"displayName":"Timotej Zaťko","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhG6XJr8UII31SY9awxZmVH0eKaIexl4APNicrOPQ=s64","userId":"16930105438254357424"}},"outputId":"49efa269-1765-4b1c-8dfb-f3969b19cf6b"},"source":["  from google.colab import drive\n","\n","# drive.mount(\"/content/gdrive\", force_remount=True)\n","drive.mount(\"/content/gdrive\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SQP0-wNGytGD"},"source":["from google.colab import auth\n","\n","\n","GCLOUD_PROJECT_ID = 'fiit-dp'\n","# ./logs and ./checkpints directories must exist in the bucket\n","GCLOUD_STORAGE_BUCKET = 'fiit-dp-training'\n","\n","\n","if USE_TPU:\n","  auth.authenticate_user()\n","\n","  !gcloud config set project '$GCLOUD_PROJECT_ID'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HX_8VkXC342m"},"source":["if USE_TPU:\n","  !echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n","  !curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n","  !apt -qq update\n","  !apt -qq install gcsfuse"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wc9nIwSh37W1"},"source":["if USE_TPU:\n","  !mkdir 'gcs_bucket'\n","  !gcsfuse '$GCLOUD_STORAGE_BUCKET' 'gcs_bucket'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xCat2MXITmZW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606430402833,"user_tz":-60,"elapsed":1918,"user":{"displayName":"Timotej Zaťko","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhG6XJr8UII31SY9awxZmVH0eKaIexl4APNicrOPQ=s64","userId":"16930105438254357424"}},"outputId":"d3156eea-21f6-4b81-9a4e-fc917008f39b"},"source":["try:\n","  # %tensorflow_version only exists in Colab.\n","  %tensorflow_version 2.x\n","except Exception:\n","  pass\n","\n","# Load the TensorBoard notebook extension.\n","%load_ext tensorboard"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The tensorboard extension is already loaded. To reload it, use:\n","  %reload_ext tensorboard\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VEIZykLN8Zou","executionInfo":{"status":"ok","timestamp":1606430407036,"user_tz":-60,"elapsed":6107,"user":{"displayName":"Timotej Zaťko","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhG6XJr8UII31SY9awxZmVH0eKaIexl4APNicrOPQ=s64","userId":"16930105438254357424"}},"outputId":"b6297141-e9db-4c46-f214-fa22e80d45da"},"source":["# Install SimpleITK\n","!pip install SimpleITK\n","\n","# Install tf-nightly\n","# !pip install tf-nightly"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: SimpleITK in /usr/local/lib/python3.6/dist-packages (2.0.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HBdfmMyPqoMZ","executionInfo":{"status":"ok","timestamp":1606430407038,"user_tz":-60,"elapsed":6095,"user":{"displayName":"Timotej Zaťko","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhG6XJr8UII31SY9awxZmVH0eKaIexl4APNicrOPQ=s64","userId":"16930105438254357424"}},"outputId":"22153feb-d470-4ba7-b250-ffda803681d8"},"source":["import tensorflow as tf\n","\n","tf.random.set_seed(RANDOM_SEED)\n","\n","print(tf.version.VERSION)\n","print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2.3.0\n","Num GPUs Available:  1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7RG8JQX2qrqw"},"source":["import os\n","\n","saliencies_and_segmentations_v2_path = \"/content/gdrive/My Drive/saliencies_and_segmentations_v2\"\n","\n","def get_path_to_saliencies_and_segmentations(sub_path):\n","  return os.path.join(saliencies_and_segmentations_v2_path, sub_path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7yQboWHOQukz"},"source":["## MRISequence\n"]},{"cell_type":"code","metadata":{"id":"aK2ZTIyr6vaj"},"source":["import os\n","import math\n","\n","import sklearn\n","import numpy as np\n","import SimpleITK as sitk\n","\n","from keras.utils import Sequence\n","\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n","from skimage.transform import resize\n","\n","\n","def process_image(path, input_shape, resize_img, normalization):\n","    x = sitk.GetArrayFromImage(sitk.ReadImage(path))\n","    if resize_img == True:\n","      x = resize(x, input_shape[:3])\n","    if normalization is not None:\n","      x = normalize(x, normalization)\n","    return np.array(x).reshape(input_shape)\n","\n","def invert_img(x):\n","    # [x, y, z, 1]\n","    return x[:, :, ::-1, :]\n","\n","def normalize(x, normalization):\n","    desc = normalization['desc']\n","    if normalization['type'] != 'standardization':\n","      return (x - desc['min']) / (desc['max'] - desc['min'])\n","    return (x - desc['mean']) / desc['std']\n","\n","def apply_augmentation(x, augmentations, name, force=False):\n","    if name == 'random_swap_hemispheres':\n","      p = augmentations['random_swap_hemispheres']\n","      if force or np.random.uniform(0) < p:\n","        return invert_img(x), True\n","    return x, False\n","\n","def apply_augmentations(x, augmentations):\n","    if augmentations is None:\n","      return x\n","\n","    for augmentation in augmentations.keys():\n","      x, applied = apply_augmentation(x, augmentations, augmentation)\n","      if applied:\n","        return x\n","\n","    return x\n","\n","# https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence\n","class MRISequence(Sequence):\n","    def __init__(self, path, batch_size, input_shape, class_names=['AD', 'CN'], \n","                 augmentations=None, augmentations_inplace=True, images=True, one_hot=True, class_weight=None,\n","                 normalization=None, resize_img=True):\n","      if one_hot == False:\n","        self.encoder = LabelEncoder()\n","        self.encoder.fit(np.array(class_names))\n","      else:\n","        self.encoder = OneHotEncoder(sparse=False)\n","        self.encoder.fit(np.array(class_names).reshape(-1, 1))\n","\n","      self.class_weight = class_weight\n","      self.one_hot = one_hot\n","      self.input_shape = input_shape\n","      self.resize_img = resize_img\n","      self.class_names = class_names\n","      self.images = images\n","      self.augmentations = augmentations\n","      self.augmentations_inplace = augmentations_inplace\n","      self.normalization = normalization\n","\n","      self.batch_size = batch_size\n","      self.images_dirs = [os.path.join(path, key) for key in os.listdir(path)]\n","        \n","    def __len__(self):\n","        return math.ceil(len(self.images_dirs) / self.batch_size)\n","        # Uncomment for debugging (when you need a smaller subset of data and faster training time)\n","        # return math.ceil(18 / self.batch_size)\n","\n","    def __getitem__(self, idx):\n","        images_dirs = self.images_dirs[idx * self.batch_size:(idx + 1) * self.batch_size]\n","        \n","        if not len(images_dirs):\n","          batch_y = np.array([]).reshape(-1)\n","          if self.one_hot:\n","            batch_y = np.array([]).reshape(-1, len(self.class_names))\n","\n","          return np.array([]).reshape(-1, *input_shape), batch_y\n","\n","        batch_y = self.__encode(np.array([self.__readfile(os.path.join(image_dir, 'real_diagnosis.txt')) for image_dir in images_dirs]))\n","\n","        # if we disabled loading images, don't do it\n","        if not self.images:\n","          batch_x = np.array([None for image_dir in images_dirs])\n","        else:\n","          batch_x = np.array([process_image(os.path.join(image_dir, 'data.nii'), self.input_shape, self.resize_img, self.normalization) for image_dir in images_dirs])\n","          \n","          if self.augmentations:\n","            if self.augmentations_inplace:\n","              batch_x = np.array([apply_augmentations(x, self.augmentations) for x in batch_x])\n","            else:\n","              new_batch_x = np.array([]).reshape(-1, *input_shape)\n","              new_batch_y = np.array([]).reshape(-1, len(self.class_names))\n","              \n","              for augmentation in self.augmentations.keys():\n","                aug_batch_x = np.array([x for x, _ in [apply_augmentation(x, augmentations, augmentation, force=True) for x in batch_x]])\n","                new_batch_x = np.concatenate((new_batch_x, aug_batch_x), axis=0)\n","                new_batch_y = np.concatenate((new_batch_y, np.copy(batch_y)), axis=0)\n","\n","              batch_x = np.concatenate((batch_x, new_batch_x), axis=0)\n","              batch_y = np.concatenate((batch_y, new_batch_y), axis=0)\n","        \n","        if self.class_weight is None:\n","          return batch_x, batch_y\n","\n","        batch_w = np.array([self.class_weight[y] for y in self.__decode(batch_y)])\n","        return batch_x, batch_y, batch_w\n","\n","    def __encode(self, labels):\n","      if self.one_hot == True:\n","        labels = labels.reshape(-1, 1)\n","      return self.encoder.transform(labels)\n","\n","    def __decode(self, labels):\n","      if self.one_hot == True:\n","          return np.argmax(labels, axis=1)\n","      return labels\n","\n","    def __readfile(self, file_path):\n","        fo = open(file_path, \"r\")\n","        c = fo.readline()\n","        fo.close()\n","        return c"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-YFnQc8j4qCI"},"source":["## seq_to_np()\n","\n","Converts sequence to numpy array. If the sequence exists in storage then load it.\n"]},{"cell_type":"code","metadata":{"id":"KDKsArUK4paD"},"source":["def seq_to_np(seq, path, name):\n","  path_x = os.path.join(path, f'{name}_x.npy')\n","  path_y = os.path.join(path, f'{name}_y.npy')\n","\n","  if os.path.exists(path_x):\n","    print(f'loading {path_x}, {path_y}...')\n","\n","    with open(path_x, 'rb') as f:\n","      train_x = np.load(f, allow_pickle=True)\n","    with open(path_y, 'rb') as f:\n","      train_y = np.load(f, allow_pickle=True)\n","    \n","    return train_x.reshape((-1, *seq.input_shape)), train_y.reshape(-1, len(seq.class_names))\n","\n","  print(f'generating {path_x}, {path_y}...')\n","\n","  train_x = []\n","  train_y = []\n","\n","  for batch_x, batch_y, *r in seq:\n","    if batch_x is not None and batch_y is not None:\n","      for x, y in zip(batch_x, batch_y):\n","          train_x.append(x)\n","          train_y.append(y)\n","\n","  with open(path_x, 'wb') as f:\n","    np.save(f, np.array(train_x))\n","  with open(path_y, 'wb') as f:\n","    np.save(f, np.array(train_y))\n","\n","  return np.array(train_x).reshape((-1, *seq.input_shape)), np.array(train_y).reshape(-1, len(seq.class_names))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ee9-RyekVYk7"},"source":["## train_test_split()"]},{"cell_type":"code","metadata":{"id":"F2C7TZdYVXni"},"source":["import os\n","import time\n","import shutil\n","import numpy as np\n","\n","from tqdm import tqdm\n","\n","\n","def train_test_split(src, dst, **kwargs):\n","  split = kwargs.get('split', (0.8, 0.1, 0.1))\n","  dirname = kwargs.get('dirname', str(int(time.time())))\n","\n","  if len(split) != 3:\n","    raise \"split mus be length of three!\"\n","\n","  if sum(split) != 1:\n","    raise \"sum of split must be 1!\"\n","\n","  dst_dir = os.path.join(dst, f'{dirname}')\n","  train_dir = os.path.join(dst_dir, 'train')\n","  test_dir = os.path.join(dst_dir, 'test')\n","  val_dir = os.path.join(dst_dir, 'val')\n","  \n","  if os.path.exists(dst_dir):\n","    print(\"not copying files since the destination directory already exists\")\n","\n","    return train_dir, test_dir, val_dir\n","\n","  os.mkdir(dst_dir)\n","  print(f\"copying to {dst_dir}...\\n\")\n","\n","  # list of directories to copy\n","  src_dirs = os.listdir(src)\n","  print('shuffling an array...')\n","  np.random.shuffle(src_dirs)\n","\n","  print('copying files...')\n","  src_dirs_count = len(src_dirs)\n","  for idx, dir in tqdm(enumerate(src_dirs), total=src_dirs_count):\n","    dst_dir = train_dir\n","\n","    if idx > split[0] * src_dirs_count:\n","      dst_dir = test_dir\n","    if idx > (split[0] + split[1]) * src_dirs_count:\n","      dst_dir = val_dir\n","\n","    shutil.copytree(os.path.join(src, dir), os.path.join(dst_dir, dir))\n","\n","  return train_dir, test_dir, val_dir\n","\n","\n","# train_test_split(saliencies_and_segmentations_v2_path, '/content/gdrive/My Drive/')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cTUOQ0mkHr6C"},"source":["import tensorflow as tf\n","\n","from keras.layers import Lambda\n","\n","\n","@tf.function\n","def random_invert_img(x, p):\n","  if tf.random.uniform([]) < p:\n","    # [x, y, z, 1]\n","    return x[:, :, ::-1, :]\n","  return x\n","\n","def RandomSwapBrainHemisphere(factor=0.5):\n","  return Lambda(lambda x: random_invert_img(x, factor))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Zha6jEp6-oo4"},"source":["## MRITensorBoardCallback"]},{"cell_type":"code","metadata":{"id":"_VtLFnGUOpZr"},"source":["import io\n","import os\n","import itertools\n","import matplotlib.pyplot as plt\n","\n","from keras.callbacks import Callback\n","\n","\n","def to_rgb_image(img, pred_label=None, true_label=None, z_index=None, add_batch_dim=True):\n","  figure = plt.figure(figsize=(4, 4))\n","  plt.imshow(img.reshape(img.shape[:-1])[z_index], cmap='gray')\n","  if true_label is not None and pred_label is not None:\n","    plt.title(f'true = {true_label}, pred = {pred_label}')\n","  return plot_to_image(figure, add_batch_dim)\n","\n","\n","def plot_to_image(figure, add_batch_dim=True):\n","  \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n","  returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n","  # Save the plot to a PNG in memory.\n","  buf = io.BytesIO()\n","  plt.savefig(buf, format='png')\n","  # Closing the figure prevents it from being displayed directly inside \n","  # the notebook.\n","  plt.close(figure)\n","  buf.seek(0)\n","  # Convert PNG buffer to TF image\n","  image = tf.image.decode_png(buf.getvalue(), channels=4)\n","  if add_batch_dim:\n","    # Add the batch dimension\n","    image = tf.expand_dims(image, 0)  \n","  return image\n","\n","\n","def plot_confusion_matrix(cm, class_names):\n","  \"\"\"\n","  Returns a matplotlib figure containing the plotted confusion matrix.\n","\n","  Args:\n","    cm (array, shape = [n, n]): a confusion matrix of integer classes\n","    class_names (array, shape = [n]): String names of the integer classes\n","  \"\"\"\n","  figure = plt.figure(figsize=(8, 8))\n","  plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n","  plt.title('Confusion matrix', fontsize=36)\n","  plt.colorbar()\n","  tick_marks = np.arange(len(class_names))\n","  plt.xticks(tick_marks, class_names, rotation=45)\n","  plt.yticks(tick_marks, class_names)\n","\n","  # Compute the labels from the normalized confusion matrix.\n","  labels = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n","\n","  # Use white text if squares are dark; otherwise black.\n","  threshold = cm.max() / 2.\n","  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","    color = 'white' if cm[i, j] > threshold else 'black'\n","    plt.text(j, i, labels[i, j], horizontalalignment='center', color=color, fontsize=18)\n","\n","  plt.tight_layout()\n","  plt.ylabel('True label', fontsize=18)\n","  plt.xlabel('Predicted label', fontsize=18)\n","  return figure\n","\n","\n","class MRITensorBoardCallback(Callback):\n","    def __init__(self, seq, model, z_index=56, max_outputs=18, freq=3, log_dir=None, debug=True):\n","        \"\"\"\n","        seq is the sequence from which is the data taken\n","        model to fit\n","        z_index is the index in the 3D image which is visualised\n","        log_dir is the where is output logged\n","        max_outputs number of images to output\n","        freq determines how frequently (each freq epoch) to outpu to tensorboard\n","        \"\"\"\n","        super(MRITensorBoardCallback, self).__init__()\n","        self.model = model\n","        self.seq = seq\n","        self.log_dir = log_dir\n","        self.z_index = z_index\n","        self.max_outputs = max_outputs\n","        self.freq = freq\n","        self.debug = debug\n","\n","    def __get_z_index(self, img):\n","      return max(min(img.shape[1], self.z_index), 0)\n","\n","    def __debug(self, msg):\n","      if self.debug:\n","        print(msg)\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","      if epoch % self.freq != 0:\n","        self.__debug('skipping evaluation of predictions to tensorboard')\n","        return\n","\n","      self.__debug(f'evaluation of predictions to tensorboard for epoch #{epoch} (no of batches is {len(self.seq)})...')\n","\n","      images = []\n","      class_names = self.seq.class_names\n","      y_pred = np.array([]).reshape(-1, len(class_names))\n","      y_true = np.array([]).reshape(-1, len(class_names))\n","\n","      # Get predictions in batches for seq\n","      for index, batch in enumerate(self.seq):\n","        x, y, _ = batch\n","        self.__debug(f'batch #{index}')\n","        # Get predictions\n","        pred = self.model.predict(x)\n","\n","        # Merge with other predictions\n","        y_true = np.concatenate([y_true, y])\n","        y_pred = np.concatenate([y_pred, pred])\n","\n","        # Encode labels\n","        true_labels = self.seq.encoder.inverse_transform(y)\n","        pred_labels = self.seq.encoder.inverse_transform(pred)\n","\n","        # Do not create more images than we output\n","        if len(images) >= self.max_outputs:\n","          continue;\n","\n","        rgb_images = [to_rgb_image(image, pred_label=pred, true_label=true, z_index=self.z_index, add_batch_dim=False) for image, pred, true in zip(x, pred_labels.reshape(-1), true_labels.reshape(-1))]\n","        for rgb_image in rgb_images:\n","          images.append(rgb_image)\n","\n","      # Create a confussion matrix\n","      cm = sklearn.metrics.confusion_matrix(np.argmax(y_true, axis=1), np.argmax(y_pred, axis=1))\n","                                                                \n","      # Log the confusion matrix as an image summary.\n","      figure = plot_confusion_matrix(cm, class_names=class_names)\n","      cm_image = plot_to_image(figure)\n","\n","      file_writer_cm = tf.summary.create_file_writer(os.path.join(self.log_dir, 'validation/confussion-matrix'))\n","      file_writer_images = tf.summary.create_file_writer(os.path.join(self.log_dir, 'validation/images'))\n","\n","      with file_writer_images.as_default():\n","        # Don't forget to reshape.\n","        images = images[0:self.max_outputs]\n","        tf.summary.image(\"Validation Images\", images, max_outputs=self.max_outputs, step=epoch)\n","\n","      # Log the confusion matrix as an image summary.\n","      with file_writer_cm.as_default():\n","        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nrikau0G5X1O"},"source":["## Evaluation"]},{"cell_type":"markdown","metadata":{"id":"tIVD4BnH5aTg"},"source":["### plot_training_history()"]},{"cell_type":"code","metadata":{"id":"G4nyOsZJ5XE9"},"source":["import os\n","import tempfile\n","import math\n","\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","\n","\n","mpl.rcParams['figure.figsize'] = (12, 10)\n","colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n","\n","\n","def plot_training_history(history):\n","  metrics = list(filter(lambda metric: 'val_' not in metric, history.history.keys()))\n","  ncols = 3\n","  nrows = math.ceil(len(metrics) / ncols)\n","  plt.figure(figsize=(nrows * 6, nrows * 6 * 1.25))\n","\n","  for n, metric in enumerate(metrics):\n","    name = metric.replace(\"_\",\" \").capitalize()\n","    plt.subplot(ncols, nrows, n + 1)\n","    plt.plot(history.epoch,  history.history[metric], color=colors[0], label='Train')\n","    plt.plot(history.epoch, history.history['val_' + metric], color=colors[0], linestyle=\"--\", label='Val')\n","    plt.xlabel('Epoch')\n","    plt.ylabel(name)\n","    plt.xlim([0, len(history.epoch)])\n","    if metric == 'loss':\n","      plt.ylim([0, plt.ylim()[1]])\n","    elif metric == 'auc':\n","      plt.ylim([0.25, 1])\n","    else:\n","      plt.ylim([0,1])\n","\n","    plt.legend()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z1mIQXi35hqH"},"source":["### custom_classification_report"]},{"cell_type":"code","metadata":{"id":"6006m0Kc5gE0"},"source":["from sklearn.metrics import classification_report, mean_squared_error, mean_squared_log_error, explained_variance_score, f1_score, accuracy_score, recall_score, make_scorer\n","\n","\n","def custom_classification_report(class_names, y_true, y_pred, **kwargs):\n","    clf_report = classification_report(\n","        y_true,\n","        y_pred,\n","        target_names=class_names,\n","        output_dict=True\n","    )\n","\n","    # Custom print because of incorrect formatting of original function\n","    for key in clf_report:\n","        if isinstance(clf_report[key], dict):\n","            print(f'\\033[1m{key}\\033[0m')\n","\n","            for metric in clf_report[key]:\n","                print(f'{metric}: {clf_report[key][metric]}')\n","        else:\n","            print(f'{key}: {clf_report[key]}')\n","\n","        print('\\n')\n","        \n","    print(f'\\033[1mF1\\033[0m')\n","    for average in ['micro', 'macro']:\n","        print(f'{average}: {f1_score(y_true, y_pred, average=average)}')\n","\n","    print('\\n')\n","    # https://en.wikipedia.org/wiki/Precision_and_recall\n","    # https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n","    sensitivity_score = make_scorer(recall_score)\n","    specificity_score = make_scorer(recall_score, pos_label=0)\n","\n","    print(f'accuracy_score: {accuracy_score(y_true, y_pred)}')\n","    # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html?highlight=recall_score\n","    print(f'sensitivity_score: {recall_score(y_true, y_pred, average=\"micro\")}')\n","    print(f'specificity_score: {recall_score(y_true, y_pred, average=\"micro\", labels=[0])}')\n","\n","    print('\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"caRucrFm5lQ2"},"source":["def show_simple_metrics(model, test_seq):\n","  baseline_results = model.evaluate(test_seq, verbose=0)\n","  for name, value in zip(model.metrics_names, baseline_results):\n","    print(f'{name}: {value}')\n","  print()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tnVxtzwV5od8"},"source":["def show_metrics(model, test_seq):\n","  y_true = np.array([]).reshape(-1, len(class_names))\n","  y_pred = np.array([]).reshape(-1, len(class_names))\n","\n","  for batch in test_seq:\n","    x, y = batch\n","\n","    pred = model.predict(x)\n","    \n","    y_true = np.concatenate([y_true, y])\n","    y_pred = np.concatenate([y_pred, pred])\n","\n","\n","  y_true_labels = test_seq.encoder.transform(test_seq.encoder.inverse_transform(y_true).reshape(-1, 1))\n","  y_pred_labels = test_seq.encoder.transform(test_seq.encoder.inverse_transform(y_pred).reshape(-1, 1))\n","\n","  # Plot the confussion matrix\n","  cm = sklearn.metrics.confusion_matrix(np.argmax(y_true, axis=1), np.argmax(y_pred, axis=1))\n","  plot_confusion_matrix(cm, class_names)\n","\n","  # Plot the metrics\n","  custom_classification_report(class_names, y_true_labels, y_pred_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mqcoI3q4Bo0u"},"source":["def show_checkpoint_metrics(model, test_seq, number):\n","  str_number = str(number)\n","  str_number = \"0\" * (4 - len(str_number)) + str_number\n","  load_checkopint(model, CHECKPOINT_DIRECTORY_LOCAL, model_key, f'cp-{str_number}.ckpt')\n","  show_metrics(model, test_seq)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sUayD_iz8Oer"},"source":["## load_checkopint"]},{"cell_type":"code","metadata":{"id":"Hgr6vIkb8NmO"},"source":["def load_checkopint(model, checkpoint_dir, model_key, ckpt_name, options=None):\n","  CHECKPOINT_PATH=os.path.join(checkpoint_dir, model_key, ckpt_name)\n","  print(f'loading checkpint from {CHECKPOINT_PATH}...')\n","  model.load_weights(CHECKPOINT_PATH, options=options)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q82dBizXvjha"},"source":["## RandomSwapBrainHemisphere"]},{"cell_type":"code","metadata":{"id":"DD2bB0tXveEK"},"source":["import tensorflow as tf\n","\n","from tensorflow.python.keras import backend as K\n","\n","\n","@tf.function\n","def random_invert_img(x, factor):\n","  if tf.random.uniform([]) < factor:\n","    # [x, y, z, 1]\n","    return x[:, :, ::-1, :]\n","  return x\n","\n","\n","class RandomSwapBrainHemisphere(tf.keras.layers.Layer):\n","  def __init__(self, input_shape, factor=0.5):\n","      super(RandomSwapBrainHemisphere, self).__init__()\n","      self.factor = factor\n","      self.__output_shape = input_shape\n","\n","  def call(self, inputs, training=True):\n","    if training is None:\n","      training = K.learning_phase()\n","\n","    if not training:\n","      return inputs\n","\n","    def flip_image_x(imgx):\n","      return tf.reshape(tf.reverse(imgx, tf.constant([0])), tf.constant([*self.__output_shape[2:]]))\n","\n","    def flip_image_z(imgz):\n","      return tf.map_fn(flip_image_x, imgz)\n","\n","    def flip_image(img):\n","        if tf.random.uniform([]) < self.factor:\n","          return tf.map_fn(flip_image_z, img)\n","        return img\n","\n","    return tf.reshape(tf.map_fn(flip_image, inputs), tf.constant([-1, *self.__output_shape]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lwfvJdjQ2yb9"},"source":["## get_description()"]},{"cell_type":"code","metadata":{"id":"aRY9obt223kh"},"source":["def get_description(norm_seq, max_samples=64):\n","  train_x = []  \n","\n","  for index, batch in enumerate(norm_seq):\n","      batch_x, _ = batch                     \n","      for x in batch_x:\n","        train_x.append(x)\n","      if max_samples is not None and len(train_x) >= max_samples:\n","        break\n","  \n","  return {'mean': np.mean(train_x), 'std': np.std(train_x), 'min': np.min(train_x), 'max': np.max(train_x) }"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9CKu9Fgh-1Gr"},"source":["## create_model()"]},{"cell_type":"code","metadata":{"id":"5VrPEseR8aMH"},"source":["def create_model(\n","                 strategy=None,\n","                 input_shape=None,\n","                 log_dir=None,\n","                 train_seq=None,\n","                 augmentation=False,\n","                 class_names=None,\n","                 output_bias=None,\n","                 batch_norm=False,\n","                 is_complex=False,\n","                 dropout=None,\n","                 l2_beta=None):\n","  \"\"\"\n","  input_shape is (z, x, y, 1)\n","  log_dir of the tensorboard logs\n","  train_seq\n","  class_names\n","  output_bias\n","  batch_normis_complex\n","  \"\"\"\n","  if input_shape is None:\n","    raise \"input_shape should not be none!\"\n","\n","  # In the original paper, they experiment with dropout and L2 regularizers\n","  # they do not specify, where they put dropout layers, and on which layers they\n","  # apply what types of regularizations\n","  model = tf.keras.models.Sequential()\n","\n","  model.add(tf.keras.layers.Input(shape=input_shape, name=\"input_layer\"))\n","\n","  if augmentation == True:\n","    # NOT WOEKING ON TPU\n","    model.add(RandomSwapBrainHemisphere(input_shape))\n","\n","  # L1, L2\n","  # In the original paper they use input_shape=(116, 113, 83, 1), however it does not match\n","  # the proportions of our input shape\n","  l2 = None\n","  if l2_beta is not None:\n","    l2 = tf.keras.regularizers.L2(l=l2_beta)\n","  model.add(tf.keras.layers.Conv3D(32, kernel_size=3, activation='relu', padding='same', kernel_regularizer=l2, input_shape=input_shape))\n","  \n","  if is_complex:\n","    l2 = None\n","    if l2_beta is not None:\n","      l2 = tf.keras.regularizers.L2(l=l2_beta)\n","    model.add(tf.keras.layers.Conv3D(32, kernel_size=3, activation='relu', padding='same', kernel_regularizer=l2))\n","\n","  if batch_norm == True:\n","    model.add(tf.keras.layers.BatchNormalization())\n","\n","  # L3\n","  model.add(tf.keras.layers.MaxPool3D(pool_size=(2, 2, 2), padding='same'))\n","\n","  # Dropout\n","  if dropout is not None:\n","    model.add(tf.keras.layers.Dropout(dropout))\n","\n","  # L4, L5\n","  l2 = None\n","  if l2_beta is not None:\n","    l2 = tf.keras.regularizers.L2(l=l2_beta)\n","  model.add(tf.keras.layers.Conv3D(64, kernel_size=3, activation='relu', padding='same', kernel_regularizer=l2))\n","\n","  if is_complex:\n","    l2 = None\n","    if l2_beta is not None:\n","      l2 = tf.keras.regularizers.L2(l=l2_beta)\n","      \n","    model.add(tf.keras.layers.Conv3D(64, kernel_size=3, activation='relu', padding='same', kernel_regularizer=l2))\n","\n","  if batch_norm == True:\n","    model.add(tf.keras.layers.BatchNormalization())\n","\n","  # L6\n","  model.add(tf.keras.layers.MaxPool3D(pool_size=(3, 3, 3)))\n","\n","  # Dropout\n","  if dropout == True:\n","    model.add(tf.keras.layers.Dropout(dropout))\n","\n","  # L7, L8\n","  l2 = None\n","  if l2_beta is not None:\n","    l2 = tf.keras.regularizers.L2(l=l2_beta)\n","\n","  model.add(tf.keras.layers.Conv3D(128, kernel_size=3, activation='relu', padding='same', kernel_regularizer=l2))\n","\n","  if is_complex:\n","    l2 = None\n","    if l2_beta is not None:\n","      l2 = tf.keras.regularizers.L2(l=l2_beta)\n","\n","    model.add(tf.keras.layers.Conv3D(128, kernel_size=3, activation='relu', padding='same', kernel_regularizer=l2))\n","\n","  if batch_norm == True:\n","    model.add(tf.keras.layers.BatchNormalization())\n","\n","  # L9\n","  model.add(tf.keras.layers.MaxPool3D(pool_size=(4, 4, 4)))\n","\n","  # Dropout\n","  if dropout is not None:\n","    model.add(tf.keras.layers.Dropout(dropout))\n","\n","  # Flatten\n","  model.add(tf.keras.layers.Flatten())\n","\n","  # L10\n","  if is_complex:\n","    l2 = None\n","    if l2_beta is not None:\n","      l2 = tf.keras.regularizers.L2(l=l2_beta)\n","    model.add(tf.keras.layers.Dense(512, kernel_regularizer=l2))\n","\n","  # Dropout\n","  if dropout is not None:\n","    model.add(tf.keras.layers.Dropout(dropout))\n","\n","  if batch_norm == True:\n","      model.add(tf.keras.layers.BatchNormalization())\n","\n","  # L11\n","  l2 = None\n","  if l2_beta is not None:\n","    l2 = tf.keras.regularizers.L2(l=l2_beta)\n","  model.add(tf.keras.layers.Dense(256, kernel_regularizer=l2))\n","\n","  # Dropout\n","  if dropout is not None:\n","    model.add(tf.keras.layers.Dropout(dropout))\n","\n","  if output_bias is not None:\n","    output_bias = tf.keras.initializers.Constant(output_bias)\n","\n","  # Output\n","  model.add(tf.keras.layers.Dense(len(class_names), activation='softmax', bias_initializer=output_bias))\n","\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tvzgaqCf1RTN"},"source":["## compile_model()"]},{"cell_type":"code","metadata":{"id":"P4aXPbE11Um_"},"source":["def compile_model(model, learning_rate=0.001, decay_steps=50, decay_rate=0.96, beta_1=0.85, beta_2=0.995):\n","    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n","        learning_rate,\n","        decay_steps=decay_steps,\n","        decay_rate=decay_rate,\n","        staircase=True\n","    )\n","\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule, beta_1=beta_1, beta_2=beta_2)\n","    # https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy\n","    loss = tf.keras.losses.CategoricalCrossentropy()\n","\n","    # Finally compile the model!\n","    model.compile(\n","      optimizer=optimizer,\n","      loss=loss,\n","      metrics=[\n","              tf.metrics.Recall(),\n","              tf.metrics.Precision(),\n","              tf.metrics.AUC(),\n","              tf.metrics.CategoricalAccuracy()\n","      ],\n","    )\n","\n","    return model, optimizer"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7xoAV4EVQxOj"},"source":["## augment()"]},{"cell_type":"code","metadata":{"id":"BxFSQVVBQwwY"},"source":["from skimage import filters\n","\n","\n","\n","def augment_invert_img(x):\n","    return x[:, :, ::-1, :]\n","\n","\n","def augment_rotate_img(x, angle=15):\n","    x_rotated = tf.keras.preprocessing.image.random_rotation(\n","        x.reshape(x.shape[:3]),\n","        angle,\n","        row_axis=1,\n","        col_axis=2,\n","        channel_axis=0,\n","        fill_mode='nearest',\n","        cval=0.0,\n","        interpolation_order=1\n","    )\n","    return x_rotated.reshape((*x_rotated.shape, 1))\n","\n","\n","def augment_random_zoom(x, zoom=0.1):\n","    x_zoomed = tf.keras.preprocessing.image.random_zoom(\n","        x.reshape(x.shape[:3]),\n","        (1 - zoom, 1 - zoom),\n","        row_axis=1,\n","        col_axis=2,\n","        channel_axis=0,\n","        fill_mode='nearest',\n","        cval=0.0,\n","        interpolation_order=1\n","    )\n","    return x_zoomed.reshape((*x_zoomed.shape, 1))\n","\n","\n","def augment_random_shear(x, angle=90):\n","  x_shared = tf.keras.preprocessing.image.random_shear(\n","      x.reshape(x.shape[:3]), angle, row_axis=1, col_axis=2, channel_axis=0, fill_mode='nearest',\n","      cval=0.0, interpolation_order=1\n","  )\n","  return x_shared.reshape((*x_shared.shape, 1))\n","\n","\n","def augment_random_gaussian_blur(x, sigma=1):\n","  x = np.array(x.reshape(x.shape[:3]))\n","  return filters.gaussian(x, multichannel=True, sigma=sigma).reshape((*x.shape, 1))\n","\n","\n","def augment(x):\n","  x = x.numpy()\n","\n","  if tf.random.uniform([], 0, 1) < 0.5:\n","    x = augment_invert_img(x)\n","  \n","  if tf.random.uniform([], 0, 1) < 0.15:\n","    x = augment_rotate_img(x, angle=2.5)\n","\n","  if tf.random.uniform([], 0, 1) < 0.15:\n","    x = augment_random_zoom(x, zoom=0.01)\n","\n","  if tf.random.uniform([], 0, 1) < 0.15:\n","    x = augment_random_shear(x, angle=2.5)\n","\n","  if tf.random.uniform([], 0, 1) < 0.15:\n","    x = augment_random_gaussian_blur(x, sigma=0.8)\n","\n","  return x\n","\n","\n","def get_class_weight(y):\n","  return class_weight[np.argmax(y.numpy(), axis=0)]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HdvCHQOuY4sH"},"source":["## train()\n"]},{"cell_type":"code","metadata":{"id":"jjg9so3_yUTW"},"source":["class MyModelCeckpoint(tf.keras.callbacks.Callback):\n","    def __init__(self, path):\n","      super(MyModelCeckpoint, self).__init__()\n","      self.path = path\n","\n","    def on_batch_end(self, epoch, logs={}):\n","        path = os.path.join(self.path, f'ckpt-{epoch}')\n","        print(f'Saving checkpoint to {path}...')\n","        model.save(path, options=tf.saved_model.SaveOptions(experimental_io_device='/job:localhost'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6SI958pF0ltd"},"source":["import datetime\n","\n","\n","def train(model,\n","          train_seq,\n","          val_seq,\n","          tpu=False,\n","          validation='val',\n","          epochs=50,\n","          patience=10,\n","          model_key=None,\n","          tensorboard_update_freq='epoch',\n","          mri_tensorboard_callback=False,\n","          model_checkpoint_callback=True,\n","          batch_size=8,\n","          workers=1):\n","  \"\"\"\n","  Start training the model.\n","  \"\"\"\n","  batch_size = train_seq.batch_size\n","  input_shape = train_seq.input_shape\n","  \n","  if model_key is None:\n","    model_key = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n","\n","  print(f'model key: {model_key}')\n","\n","  checkpoint_dir = os.path.join(CHECKPOINT_DIRECTORY, model_key)\n","  log_dir = os.path.join(LOG_DIRECTORY, model_key)\n","\n","  print(f'checkpoint dir - {checkpoint_dir}')\n","  print(f'log dir - {log_dir}')\n","\n","  callbacks = [\n","      # https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping \n","      tf.keras.callbacks.EarlyStopping(\n","          monitor='val_loss',\n","          patience=patience, # Number of epochs with no improvement after which training will be stopped.\n","          restore_best_weights=True,\n","      ),\n","  ]\n","  \n","  # https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard\n","  callbacks.append(tf.keras.callbacks.TensorBoard(\n","      log_dir=log_dir,\n","      update_freq=tensorboard_update_freq, # batch frequency number / 'epoch'\n","      histogram_freq=0,\n","      profile_batch=0\n","  )),\n","\n","  if model_checkpoint_callback is not False:\n","    callbacks.append(tf.keras.callbacks.ModelCheckpoint(\n","        os.path.join(checkpoint_dir, 'cp-{epoch:04d}.ckpt'),          \n","        monitor='val_loss',\n","        save_weights_only=True,\n","        verbose=2,\n","        save_best_only=model_checkpoint_callback != 'save_best_only'\n","    )),\n","\n","  if mri_tensorboard_callback:\n","    callbacks.append(MRITensorBoardCallback(val_seq, model, z_index=input_shape[0] // 2, freq=1, log_dir=log_dir, debug=False))\n","\n","    # TODO: the path might be configurable in the future\n","    train_x, train_y = seq_to_np(train_seq, os.path.join('/content/gdrive/My Drive/data-v2'), 'train')\n","    val_x, val_y = seq_to_np(val_seq, os.path.join('/content/gdrive/My Drive/data-v2'), 'val')\n","\n","    if validation == 'val_test':\n","      test_x, test_y = seq_to_np(test_seq, os.path.join('/content/gdrive/My Drive/data-v2'), 'test')\n","\n","      val_x = np.concatenate([test_x, val_x], axis=0)\n","      val_y = np.concatenate([test_y, val_y], axis=0)\n","\n","    print(f'train: {len(train_x)}, val: {len(val_x)}')\n","\n","  train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n","  if USE_TPU:\n","    train_dataset = train_dataset.map(lambda x, y: (tf.py_function(func=augment, inp=[x], Tout=tf.float32), y))\n","  else:\n","    train_dataset = train_dataset.map(lambda x, y: (augment_invert_img(x) if tf.random.uniform([], 0, 1) > 0.5 else x, y, tf.py_function(func=get_class_weight, inp=[y], Tout=tf.float32)))\n","  batched_train = train_dataset.batch(batch_size)\n","\n","  val_dataset = tf.data.Dataset.from_tensor_slices((val_x, val_y))\n","  val_dataset = val_dataset.map(lambda x, y: (x, y, tf.py_function(func=get_class_weight, inp=[y], Tout=tf.float32)))\n","  batched_val = val_dataset.batch(batch_size)\n","\n","  # train the model\n","  # https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit\n","  if not tpu:\n","    print('training on gpu...')\n","    history = model.fit(\n","        batched_train,\n","        validation_data=batched_val,\n","        # batch_size=tpu_config['batch_size'],\n","        epochs=epochs,\n","        # class_weight=class_weight,\n","        callbacks=callbacks)\n","  else:\n","    print('training on tpu...')\n","\n","    history = model.fit(\n","        batched_train,\n","        # train_x,\n","        # train_y,\n","        validation_data=validation_data,\n","        # batch_size=tpu_config['batch_size'],\n","        epochs=epochs,\n","        class_weight=class_weight,\n","        callbacks=callbacks)\n","\n","  return model, checkpoint_dir, history"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d819KbrkjPh1"},"source":["## Training"]},{"cell_type":"markdown","metadata":{"id":"6ntdctEoZRK_"},"source":["### Setup"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9vnEGUEAQJr4","executionInfo":{"status":"ok","timestamp":1606430407658,"user_tz":-60,"elapsed":6543,"user":{"displayName":"Timotej Zaťko","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhG6XJr8UII31SY9awxZmVH0eKaIexl4APNicrOPQ=s64","userId":"16930105438254357424"}},"outputId":"5fb3fadb-7979-4cc4-fb1d-14cc2e48c7b4"},"source":["%%time\n","\n","import datetime\n","\n","\n","# https://github.com/timzatko/fiit-nsiete/blob/master/src/model.py\n","\n","DEFAULT_LOCAL_CHECKPOINT_DIRECTORY = os.path.join('/content/gdrive/My Drive/', 'checkpoints')\n","DEFAULT_LOCAL_BCKP_CHECKPOINT_DIRECTORY = os.path.join('/content/gdrive/My Drive/', 'bckp-checkpoints')\n","DEFAULT_TPU_CHECKPOINT_DIRECTORY = os.path.join('/content/gcs_bucket/', 'checkpoints')\n","\n","# constants\n","LOG_DIRECTORY = os.path.join('/content/gdrive/My Drive/', 'logs')\n","CHECKPOINT_DIRECTORY = DEFAULT_LOCAL_CHECKPOINT_DIRECTORY\n","LOG_DIRECTORY_LOCAL = LOG_DIRECTORY\n","CHECKPOINT_DIRECTORY_LOCAL = CHECKPOINT_DIRECTORY\n","\n","if not os.path.exists(CHECKPOINT_DIRECTORY):\n","  os.mkdir(CHECKPOINT_DIRECTORY)\n","\n","if not os.path.exists(LOG_DIRECTORY):\n","  os.mkdir(LOG_DIRECTORY)\n","\n","if USE_TPU:\n","  # GCS BUCKET MUST BE MOUNTED!\n","  LOG_DIRECTORY = 'gs://fiit-dp-training/logs'\n","  CHECKPOINT_DIRECTORY = 'gs://fiit-dp-training/checkpoints'\n","  LOG_DIRECTORY_LOCAL = os.path.join('/content/gcs_bucket/', 'logs')\n","  CHECKPOINT_DIRECTORY_LOCAL = DEFAULT_TPU_CHECKPOINT_DIRECTORY\n","\n","class_names = ['AD', 'CN']\n","\n","# get paths to data\n","train_dir, test_dir, val_dir = train_test_split(saliencies_and_segmentations_v2_path, '/content/gdrive/My Drive/', split=(0.8, 0.15, 0.05), dirname='data-v2')\n","\n","# set the batch size for mri seq\n","# this does not apply when training with TPU!\n","batch_size = 12\n","input_shape = (112, 112, 105, 1)\n","resize_img=True\n","\n","# set the batch size for mri seq\n","# input_shape = (160, 160, 150, 1)\n","# resize_img=False\n","\n","if USE_TPU:\n","  batch_size = 32\n","\n","# if y is one-hot encoded or just scalar number\n","one_hot = True\n","\n","# class weights (see analysis notebook)\n","class_weight = {0: 0.8271604938271606, 1: 1.2641509433962266}\n","\n","# description statistics of the dataset\n","desc = {'mean': -3.6344006e-09, 'std': 1.0000092, 'min': -1.4982183, 'max': 10.744175}\n","\n","if 'desc' not in locals():\n","  print('initializing desc...')\n","  desc = get_description(MRISequence(\n","    train_dir,\n","    64,\n","    class_names=class_names,\n","    input_shape=input_shape), max_samples=None)\n","  print(desc)\n","  \n","normalization={'type':'normalization', 'desc': desc }\n","# normalization={'type':'standardization', 'desc':desc }\n","\n","augmentations={'random_swap_hemispheres': 0.5}\n","\n","print('initializing train_seq...')\n","# initialize sequence\n","train_seq = MRISequence(\n","    train_dir,\n","    batch_size,\n","    class_names=class_names,\n","    augmentations=augmentations,\n","    augmentations_inplace=not USE_TPU,\n","    input_shape=input_shape,\n","    resize_img=resize_img,\n","    one_hot=one_hot,\n","    class_weight=class_weight,\n","    normalization=normalization)\n","print('initializing val_seq...')\n","val_seq = MRISequence(\n","    val_dir,\n","    batch_size,\n","    class_names=class_names,\n","    input_shape=input_shape,\n","    resize_img=resize_img,\n","    one_hot=one_hot,\n","    class_weight=class_weight,\n","    normalization=normalization)\n","print('initializing test_seq...')\n","test_seq = MRISequence(\n","    test_dir,\n","    batch_size,\n","    class_names=class_names,\n","    input_shape=input_shape,\n","    resize_img=resize_img,\n","    one_hot=one_hot,\n","    normalization=normalization)\n","\n","model_key = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n","log_dir = os.path.join(LOG_DIRECTORY, model_key)\n","print(f'log_dir: {log_dir}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["not copying files since the destination directory already exists\n","initializing train_seq...\n","initializing val_seq...\n","initializing test_seq...\n","log_dir: /content/gdrive/My Drive/logs/20201126-224007\n","CPU times: user 2.87 ms, sys: 1.04 ms, total: 3.91 ms\n","Wall time: 97.5 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"R6NGTMc31Ppw"},"source":["# https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#class_weights\n","# pos / neg\n","initial_bias = np.log([243/159, 159/243])\n","\n","model_config = {\n","    'input_shape': input_shape,\n","    'log_dir': log_dir, \n","    'train_seq': train_seq,\n","    'class_names': class_names,\n","    # 'l2_beta': 0.001,\n","    'l2_beta': 0.00025,\n","    # 'l2_beta': None,\n","    'dropout': 0.25,\n","    # 'dropout': None,\n","    'output_bias': initial_bias,\n","    # 'output_bias': None,\n","    # https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization\n","    'batch_norm': False if USE_TPU else False,\n","    'is_complex': False, # a complex layer from the paper, max batch_size is 3\n","}\n","\n","compile_config = {\n","    # default is 0.001\n","    # 'learning_rate': 0.000075,\n","    # 'learning_rate': 0.00025,\n","    'learning_rate': 0.00030,\n","    'decay_steps': 10,\n","    'decay_rate': 0.96,\n","    # 'beta_1': 0.85,\n","    'beta_1': 0.90,\n","    # 'beta_2': 0.990,\n","    'beta_2': 0.999,\n","}\n","\n","train_config = {\n","    'tpu': USE_TPU,\n","    'model_key': model_key,\n","    'validation': 'val_test',\n","    'epochs': 150 if USE_TPU else 200,\n","    'patience': 150,\n","    'tensorboard_update_freq': 'epoch' if USE_TPU else 'epoch', # since TPU is hell fast, update tensorboard only on epoch end\n","    'mri_tensorboard_callback': not USE_TPU,\n","    'model_checkpoint_callback': 'save_best_only',\n","    # 'model_checkpoint_callback': False,\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4DedIYBT3TQK"},"source":["### GPU"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-UnG2HphL0CC","executionInfo":{"status":"ok","timestamp":1606430407660,"user_tz":-60,"elapsed":6528,"user":{"displayName":"Timotej Zaťko","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhG6XJr8UII31SY9awxZmVH0eKaIexl4APNicrOPQ=s64","userId":"16930105438254357424"}},"outputId":"0b358793-87d4-42cc-9d4a-d959d0f44f16"},"source":["if not USE_TPU:\n","  model = create_model(**model_config)\n","  model, *_ = compile_model(model, **compile_config)\n","  model.build(input_shape=input_shape)\n","  model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv3d_6 (Conv3D)            (None, 112, 112, 105, 32) 896       \n","_________________________________________________________________\n","max_pooling3d_6 (MaxPooling3 (None, 56, 56, 53, 32)    0         \n","_________________________________________________________________\n","dropout_8 (Dropout)          (None, 56, 56, 53, 32)    0         \n","_________________________________________________________________\n","conv3d_7 (Conv3D)            (None, 56, 56, 53, 64)    55360     \n","_________________________________________________________________\n","max_pooling3d_7 (MaxPooling3 (None, 18, 18, 17, 64)    0         \n","_________________________________________________________________\n","conv3d_8 (Conv3D)            (None, 18, 18, 17, 128)   221312    \n","_________________________________________________________________\n","max_pooling3d_8 (MaxPooling3 (None, 4, 4, 4, 128)      0         \n","_________________________________________________________________\n","dropout_9 (Dropout)          (None, 4, 4, 4, 128)      0         \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 8192)              0         \n","_________________________________________________________________\n","dropout_10 (Dropout)         (None, 8192)              0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 256)               2097408   \n","_________________________________________________________________\n","dropout_11 (Dropout)         (None, 256)               0         \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 2)                 514       \n","=================================================================\n","Total params: 2,375,490\n","Trainable params: 2,375,490\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bCcrOsnZ8aMc"},"source":["if not USE_TPU and not TRAIN_MODEL:\n","  load_checkopint(model, DEFAULT_LOCAL_BCKP_CHECKPOINT_DIRECTORY, '20201113-091456', 'cp-0063.ckpt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"iM0lVSnJ568Y","executionInfo":{"status":"error","timestamp":1606431462596,"user_tz":-60,"elapsed":1061440,"user":{"displayName":"Timotej Zaťko","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhG6XJr8UII31SY9awxZmVH0eKaIexl4APNicrOPQ=s64","userId":"16930105438254357424"}},"outputId":"d64f29dd-9255-4733-a7a6-f060cb212b8f"},"source":["%%time\n","\n","if not USE_TPU and TRAIN_MODEL:\n","  # tf.executing_eagerly()\n","  \n","  \n","  model, checkpoint_dir, history = train(\n","      model,\n","      train_seq,\n","      val_seq,\n","      **train_config\n","  )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["model key: 20201126-224007\n","checkpoint dir - /content/gdrive/My Drive/checkpoints/20201126-224007\n","log dir - /content/gdrive/My Drive/logs/20201126-224007\n","loading /content/gdrive/My Drive/data-v2/train_x.npy, /content/gdrive/My Drive/data-v2/train_y.npy...\n","loading /content/gdrive/My Drive/data-v2/val_x.npy, /content/gdrive/My Drive/data-v2/val_y.npy...\n","loading /content/gdrive/My Drive/data-v2/test_x.npy, /content/gdrive/My Drive/data-v2/test_y.npy...\n","train: 402, val: 100\n","training on gpu...\n","Epoch 1/200\n"," 2/34 [>.............................] - ETA: 3s - loss: 0.9346 - recall_2: 0.5000 - precision_2: 0.5000 - auc_2: 0.5816 - categorical_accuracy: 0.5000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0763s vs `on_train_batch_end` time: 0.1405s). Check your callbacks.\n","34/34 [==============================] - ETA: 0s - loss: 0.8655 - recall_2: 0.5796 - precision_2: 0.5796 - auc_2: 0.5769 - categorical_accuracy: 0.5796\n","Epoch 00001: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0001.ckpt\n","34/34 [==============================] - 18s 521ms/step - loss: 0.8655 - recall_2: 0.5796 - precision_2: 0.5796 - auc_2: 0.5769 - categorical_accuracy: 0.5796 - val_loss: 0.7940 - val_recall_2: 0.6800 - val_precision_2: 0.6800 - val_auc_2: 0.6943 - val_categorical_accuracy: 0.6800\n","Epoch 2/200\n","34/34 [==============================] - ETA: 0s - loss: 0.8265 - recall_2: 0.5050 - precision_2: 0.5050 - auc_2: 0.4927 - categorical_accuracy: 0.5050\n","Epoch 00002: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0002.ckpt\n","34/34 [==============================] - 17s 496ms/step - loss: 0.8265 - recall_2: 0.5050 - precision_2: 0.5050 - auc_2: 0.4927 - categorical_accuracy: 0.5050 - val_loss: 0.7811 - val_recall_2: 0.6800 - val_precision_2: 0.6800 - val_auc_2: 0.7069 - val_categorical_accuracy: 0.6800\n","Epoch 3/200\n","34/34 [==============================] - ETA: 0s - loss: 0.8131 - recall_2: 0.5224 - precision_2: 0.5224 - auc_2: 0.5298 - categorical_accuracy: 0.5224\n","Epoch 00003: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0003.ckpt\n","34/34 [==============================] - 17s 496ms/step - loss: 0.8131 - recall_2: 0.5224 - precision_2: 0.5224 - auc_2: 0.5298 - categorical_accuracy: 0.5224 - val_loss: 0.7708 - val_recall_2: 0.6800 - val_precision_2: 0.6800 - val_auc_2: 0.7013 - val_categorical_accuracy: 0.6800\n","Epoch 4/200\n","34/34 [==============================] - ETA: 0s - loss: 0.8091 - recall_2: 0.5149 - precision_2: 0.5149 - auc_2: 0.5046 - categorical_accuracy: 0.5149\n","Epoch 00004: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0004.ckpt\n","34/34 [==============================] - 17s 488ms/step - loss: 0.8091 - recall_2: 0.5149 - precision_2: 0.5149 - auc_2: 0.5046 - categorical_accuracy: 0.5149 - val_loss: 0.7627 - val_recall_2: 0.6800 - val_precision_2: 0.6800 - val_auc_2: 0.7073 - val_categorical_accuracy: 0.6800\n","Epoch 5/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7963 - recall_2: 0.5299 - precision_2: 0.5299 - auc_2: 0.5352 - categorical_accuracy: 0.5299\n","Epoch 00005: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0005.ckpt\n","34/34 [==============================] - 17s 489ms/step - loss: 0.7963 - recall_2: 0.5299 - precision_2: 0.5299 - auc_2: 0.5352 - categorical_accuracy: 0.5299 - val_loss: 0.7567 - val_recall_2: 0.6800 - val_precision_2: 0.6800 - val_auc_2: 0.7031 - val_categorical_accuracy: 0.6800\n","Epoch 6/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7907 - recall_2: 0.5448 - precision_2: 0.5448 - auc_2: 0.5455 - categorical_accuracy: 0.5448\n","Epoch 00006: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0006.ckpt\n","34/34 [==============================] - 17s 496ms/step - loss: 0.7907 - recall_2: 0.5448 - precision_2: 0.5448 - auc_2: 0.5455 - categorical_accuracy: 0.5448 - val_loss: 0.7520 - val_recall_2: 0.6800 - val_precision_2: 0.6800 - val_auc_2: 0.7025 - val_categorical_accuracy: 0.6800\n","Epoch 7/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7878 - recall_2: 0.5448 - precision_2: 0.5448 - auc_2: 0.5388 - categorical_accuracy: 0.5448\n","Epoch 00007: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0007.ckpt\n","34/34 [==============================] - 17s 501ms/step - loss: 0.7878 - recall_2: 0.5448 - precision_2: 0.5448 - auc_2: 0.5388 - categorical_accuracy: 0.5448 - val_loss: 0.7477 - val_recall_2: 0.6800 - val_precision_2: 0.6800 - val_auc_2: 0.7051 - val_categorical_accuracy: 0.6800\n","Epoch 8/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7869 - recall_2: 0.5149 - precision_2: 0.5149 - auc_2: 0.5299 - categorical_accuracy: 0.5149\n","Epoch 00008: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0008.ckpt\n","34/34 [==============================] - 17s 506ms/step - loss: 0.7869 - recall_2: 0.5149 - precision_2: 0.5149 - auc_2: 0.5299 - categorical_accuracy: 0.5149 - val_loss: 0.7446 - val_recall_2: 0.6800 - val_precision_2: 0.6800 - val_auc_2: 0.7097 - val_categorical_accuracy: 0.6800\n","Epoch 9/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7793 - recall_2: 0.5274 - precision_2: 0.5274 - auc_2: 0.5510 - categorical_accuracy: 0.5274\n","Epoch 00009: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0009.ckpt\n","34/34 [==============================] - 17s 504ms/step - loss: 0.7793 - recall_2: 0.5274 - precision_2: 0.5274 - auc_2: 0.5510 - categorical_accuracy: 0.5274 - val_loss: 0.7416 - val_recall_2: 0.6800 - val_precision_2: 0.6800 - val_auc_2: 0.7121 - val_categorical_accuracy: 0.6800\n","Epoch 10/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7777 - recall_2: 0.5323 - precision_2: 0.5323 - auc_2: 0.5488 - categorical_accuracy: 0.5323\n","Epoch 00010: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0010.ckpt\n","34/34 [==============================] - 17s 500ms/step - loss: 0.7777 - recall_2: 0.5323 - precision_2: 0.5323 - auc_2: 0.5488 - categorical_accuracy: 0.5323 - val_loss: 0.7392 - val_recall_2: 0.6800 - val_precision_2: 0.6800 - val_auc_2: 0.7114 - val_categorical_accuracy: 0.6800\n","Epoch 11/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7732 - recall_2: 0.5547 - precision_2: 0.5547 - auc_2: 0.5658 - categorical_accuracy: 0.5547\n","Epoch 00011: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0011.ckpt\n","34/34 [==============================] - 17s 503ms/step - loss: 0.7732 - recall_2: 0.5547 - precision_2: 0.5547 - auc_2: 0.5658 - categorical_accuracy: 0.5547 - val_loss: 0.7374 - val_recall_2: 0.6800 - val_precision_2: 0.6800 - val_auc_2: 0.7109 - val_categorical_accuracy: 0.6800\n","Epoch 12/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7657 - recall_2: 0.5522 - precision_2: 0.5522 - auc_2: 0.5785 - categorical_accuracy: 0.5522\n","Epoch 00012: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0012.ckpt\n","34/34 [==============================] - 29s 864ms/step - loss: 0.7657 - recall_2: 0.5522 - precision_2: 0.5522 - auc_2: 0.5785 - categorical_accuracy: 0.5522 - val_loss: 0.7356 - val_recall_2: 0.6800 - val_precision_2: 0.6800 - val_auc_2: 0.7101 - val_categorical_accuracy: 0.6800\n","Epoch 13/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7579 - recall_2: 0.5771 - precision_2: 0.5771 - auc_2: 0.6110 - categorical_accuracy: 0.5771\n","Epoch 00013: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0013.ckpt\n","34/34 [==============================] - 17s 492ms/step - loss: 0.7579 - recall_2: 0.5771 - precision_2: 0.5771 - auc_2: 0.6110 - categorical_accuracy: 0.5771 - val_loss: 0.7342 - val_recall_2: 0.6900 - val_precision_2: 0.6900 - val_auc_2: 0.7099 - val_categorical_accuracy: 0.6900\n","Epoch 14/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7568 - recall_2: 0.5945 - precision_2: 0.5945 - auc_2: 0.6097 - categorical_accuracy: 0.5945\n","Epoch 00014: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0014.ckpt\n","34/34 [==============================] - 17s 489ms/step - loss: 0.7568 - recall_2: 0.5945 - precision_2: 0.5945 - auc_2: 0.6097 - categorical_accuracy: 0.5945 - val_loss: 0.7331 - val_recall_2: 0.6900 - val_precision_2: 0.6900 - val_auc_2: 0.7106 - val_categorical_accuracy: 0.6900\n","Epoch 15/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7564 - recall_2: 0.5746 - precision_2: 0.5746 - auc_2: 0.6085 - categorical_accuracy: 0.5746\n","Epoch 00015: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0015.ckpt\n","34/34 [==============================] - 17s 491ms/step - loss: 0.7564 - recall_2: 0.5746 - precision_2: 0.5746 - auc_2: 0.6085 - categorical_accuracy: 0.5746 - val_loss: 0.7313 - val_recall_2: 0.6900 - val_precision_2: 0.6900 - val_auc_2: 0.7125 - val_categorical_accuracy: 0.6900\n","Epoch 16/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7531 - recall_2: 0.5896 - precision_2: 0.5896 - auc_2: 0.6091 - categorical_accuracy: 0.5896\n","Epoch 00016: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0016.ckpt\n","34/34 [==============================] - 17s 508ms/step - loss: 0.7531 - recall_2: 0.5896 - precision_2: 0.5896 - auc_2: 0.6091 - categorical_accuracy: 0.5896 - val_loss: 0.7302 - val_recall_2: 0.6900 - val_precision_2: 0.6900 - val_auc_2: 0.7129 - val_categorical_accuracy: 0.6900\n","Epoch 17/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7528 - recall_2: 0.5970 - precision_2: 0.5970 - auc_2: 0.6104 - categorical_accuracy: 0.5970\n","Epoch 00017: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0017.ckpt\n","34/34 [==============================] - 17s 502ms/step - loss: 0.7528 - recall_2: 0.5970 - precision_2: 0.5970 - auc_2: 0.6104 - categorical_accuracy: 0.5970 - val_loss: 0.7295 - val_recall_2: 0.7100 - val_precision_2: 0.7100 - val_auc_2: 0.7153 - val_categorical_accuracy: 0.7100\n","Epoch 18/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7494 - recall_2: 0.5796 - precision_2: 0.5796 - auc_2: 0.6139 - categorical_accuracy: 0.5796\n","Epoch 00018: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0018.ckpt\n","34/34 [==============================] - 17s 488ms/step - loss: 0.7494 - recall_2: 0.5796 - precision_2: 0.5796 - auc_2: 0.6139 - categorical_accuracy: 0.5796 - val_loss: 0.7285 - val_recall_2: 0.6900 - val_precision_2: 0.6900 - val_auc_2: 0.7152 - val_categorical_accuracy: 0.6900\n","Epoch 19/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7421 - recall_2: 0.6045 - precision_2: 0.6045 - auc_2: 0.6417 - categorical_accuracy: 0.6045\n","Epoch 00019: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0019.ckpt\n","34/34 [==============================] - 17s 486ms/step - loss: 0.7421 - recall_2: 0.6045 - precision_2: 0.6045 - auc_2: 0.6417 - categorical_accuracy: 0.6045 - val_loss: 0.7281 - val_recall_2: 0.6800 - val_precision_2: 0.6800 - val_auc_2: 0.7142 - val_categorical_accuracy: 0.6800\n","Epoch 20/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7428 - recall_2: 0.5846 - precision_2: 0.5846 - auc_2: 0.6343 - categorical_accuracy: 0.5846\n","Epoch 00020: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0020.ckpt\n","34/34 [==============================] - 17s 489ms/step - loss: 0.7428 - recall_2: 0.5846 - precision_2: 0.5846 - auc_2: 0.6343 - categorical_accuracy: 0.5846 - val_loss: 0.7278 - val_recall_2: 0.6900 - val_precision_2: 0.6900 - val_auc_2: 0.7125 - val_categorical_accuracy: 0.6900\n","Epoch 21/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7352 - recall_2: 0.6393 - precision_2: 0.6393 - auc_2: 0.6601 - categorical_accuracy: 0.6393\n","Epoch 00021: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0021.ckpt\n","34/34 [==============================] - 17s 487ms/step - loss: 0.7352 - recall_2: 0.6393 - precision_2: 0.6393 - auc_2: 0.6601 - categorical_accuracy: 0.6393 - val_loss: 0.7273 - val_recall_2: 0.6700 - val_precision_2: 0.6700 - val_auc_2: 0.7090 - val_categorical_accuracy: 0.6700\n","Epoch 22/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7431 - recall_2: 0.5796 - precision_2: 0.5796 - auc_2: 0.6315 - categorical_accuracy: 0.5796\n","Epoch 00022: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0022.ckpt\n","34/34 [==============================] - 17s 506ms/step - loss: 0.7431 - recall_2: 0.5796 - precision_2: 0.5796 - auc_2: 0.6315 - categorical_accuracy: 0.5796 - val_loss: 0.7266 - val_recall_2: 0.6700 - val_precision_2: 0.6700 - val_auc_2: 0.7115 - val_categorical_accuracy: 0.6700\n","Epoch 23/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7305 - recall_2: 0.6144 - precision_2: 0.6144 - auc_2: 0.6638 - categorical_accuracy: 0.6144\n","Epoch 00023: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0023.ckpt\n","34/34 [==============================] - 17s 485ms/step - loss: 0.7305 - recall_2: 0.6144 - precision_2: 0.6144 - auc_2: 0.6638 - categorical_accuracy: 0.6144 - val_loss: 0.7272 - val_recall_2: 0.6600 - val_precision_2: 0.6600 - val_auc_2: 0.7003 - val_categorical_accuracy: 0.6600\n","Epoch 24/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7377 - recall_2: 0.5697 - precision_2: 0.5697 - auc_2: 0.6335 - categorical_accuracy: 0.5697\n","Epoch 00024: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0024.ckpt\n","34/34 [==============================] - 17s 494ms/step - loss: 0.7377 - recall_2: 0.5697 - precision_2: 0.5697 - auc_2: 0.6335 - categorical_accuracy: 0.5697 - val_loss: 0.7264 - val_recall_2: 0.6700 - val_precision_2: 0.6700 - val_auc_2: 0.7016 - val_categorical_accuracy: 0.6700\n","Epoch 25/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7388 - recall_2: 0.6020 - precision_2: 0.6020 - auc_2: 0.6385 - categorical_accuracy: 0.6020\n","Epoch 00025: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0025.ckpt\n","34/34 [==============================] - 16s 485ms/step - loss: 0.7388 - recall_2: 0.6020 - precision_2: 0.6020 - auc_2: 0.6385 - categorical_accuracy: 0.6020 - val_loss: 0.7259 - val_recall_2: 0.6700 - val_precision_2: 0.6700 - val_auc_2: 0.7025 - val_categorical_accuracy: 0.6700\n","Epoch 26/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7298 - recall_2: 0.6020 - precision_2: 0.6020 - auc_2: 0.6609 - categorical_accuracy: 0.6020\n","Epoch 00026: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0026.ckpt\n","34/34 [==============================] - 17s 486ms/step - loss: 0.7298 - recall_2: 0.6020 - precision_2: 0.6020 - auc_2: 0.6609 - categorical_accuracy: 0.6020 - val_loss: 0.7259 - val_recall_2: 0.6700 - val_precision_2: 0.6700 - val_auc_2: 0.7023 - val_categorical_accuracy: 0.6700\n","Epoch 27/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7266 - recall_2: 0.6418 - precision_2: 0.6418 - auc_2: 0.6757 - categorical_accuracy: 0.6418\n","Epoch 00027: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0027.ckpt\n","34/34 [==============================] - 17s 488ms/step - loss: 0.7266 - recall_2: 0.6418 - precision_2: 0.6418 - auc_2: 0.6757 - categorical_accuracy: 0.6418 - val_loss: 0.7256 - val_recall_2: 0.6700 - val_precision_2: 0.6700 - val_auc_2: 0.7039 - val_categorical_accuracy: 0.6700\n","Epoch 28/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7197 - recall_2: 0.6418 - precision_2: 0.6418 - auc_2: 0.6917 - categorical_accuracy: 0.6418\n","Epoch 00028: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0028.ckpt\n","34/34 [==============================] - 17s 510ms/step - loss: 0.7197 - recall_2: 0.6418 - precision_2: 0.6418 - auc_2: 0.6917 - categorical_accuracy: 0.6418 - val_loss: 0.7258 - val_recall_2: 0.6200 - val_precision_2: 0.6200 - val_auc_2: 0.6963 - val_categorical_accuracy: 0.6200\n","Epoch 29/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7259 - recall_2: 0.6119 - precision_2: 0.6119 - auc_2: 0.6694 - categorical_accuracy: 0.6119\n","Epoch 00029: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0029.ckpt\n","34/34 [==============================] - 17s 496ms/step - loss: 0.7259 - recall_2: 0.6119 - precision_2: 0.6119 - auc_2: 0.6694 - categorical_accuracy: 0.6119 - val_loss: 0.7256 - val_recall_2: 0.6100 - val_precision_2: 0.6100 - val_auc_2: 0.6962 - val_categorical_accuracy: 0.6100\n","Epoch 30/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7325 - recall_2: 0.5871 - precision_2: 0.5871 - auc_2: 0.6519 - categorical_accuracy: 0.5871\n","Epoch 00030: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0030.ckpt\n","34/34 [==============================] - 17s 488ms/step - loss: 0.7325 - recall_2: 0.5871 - precision_2: 0.5871 - auc_2: 0.6519 - categorical_accuracy: 0.5871 - val_loss: 0.7257 - val_recall_2: 0.6200 - val_precision_2: 0.6200 - val_auc_2: 0.6923 - val_categorical_accuracy: 0.6200\n","Epoch 31/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7328 - recall_2: 0.5920 - precision_2: 0.5920 - auc_2: 0.6476 - categorical_accuracy: 0.5920\n","Epoch 00031: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0031.ckpt\n","34/34 [==============================] - 16s 485ms/step - loss: 0.7328 - recall_2: 0.5920 - precision_2: 0.5920 - auc_2: 0.6476 - categorical_accuracy: 0.5920 - val_loss: 0.7255 - val_recall_2: 0.6200 - val_precision_2: 0.6200 - val_auc_2: 0.6912 - val_categorical_accuracy: 0.6200\n","Epoch 32/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7233 - recall_2: 0.6318 - precision_2: 0.6318 - auc_2: 0.6749 - categorical_accuracy: 0.6318\n","Epoch 00032: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0032.ckpt\n","34/34 [==============================] - 17s 485ms/step - loss: 0.7233 - recall_2: 0.6318 - precision_2: 0.6318 - auc_2: 0.6749 - categorical_accuracy: 0.6318 - val_loss: 0.7254 - val_recall_2: 0.6200 - val_precision_2: 0.6200 - val_auc_2: 0.6911 - val_categorical_accuracy: 0.6200\n","Epoch 33/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7301 - recall_2: 0.5846 - precision_2: 0.5846 - auc_2: 0.6448 - categorical_accuracy: 0.5846\n","Epoch 00033: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0033.ckpt\n","34/34 [==============================] - 17s 488ms/step - loss: 0.7301 - recall_2: 0.5846 - precision_2: 0.5846 - auc_2: 0.6448 - categorical_accuracy: 0.5846 - val_loss: 0.7251 - val_recall_2: 0.6200 - val_precision_2: 0.6200 - val_auc_2: 0.6928 - val_categorical_accuracy: 0.6200\n","Epoch 34/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7218 - recall_2: 0.6443 - precision_2: 0.6443 - auc_2: 0.6831 - categorical_accuracy: 0.6443\n","Epoch 00034: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0034.ckpt\n","34/34 [==============================] - 17s 489ms/step - loss: 0.7218 - recall_2: 0.6443 - precision_2: 0.6443 - auc_2: 0.6831 - categorical_accuracy: 0.6443 - val_loss: 0.7250 - val_recall_2: 0.6200 - val_precision_2: 0.6200 - val_auc_2: 0.6921 - val_categorical_accuracy: 0.6200\n","Epoch 35/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7315 - recall_2: 0.6045 - precision_2: 0.6045 - auc_2: 0.6537 - categorical_accuracy: 0.6045\n","Epoch 00035: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0035.ckpt\n","34/34 [==============================] - 16s 485ms/step - loss: 0.7315 - recall_2: 0.6045 - precision_2: 0.6045 - auc_2: 0.6537 - categorical_accuracy: 0.6045 - val_loss: 0.7249 - val_recall_2: 0.6200 - val_precision_2: 0.6200 - val_auc_2: 0.6925 - val_categorical_accuracy: 0.6200\n","Epoch 36/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7204 - recall_2: 0.6169 - precision_2: 0.6169 - auc_2: 0.6821 - categorical_accuracy: 0.6169\n","Epoch 00036: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0036.ckpt\n","34/34 [==============================] - 17s 511ms/step - loss: 0.7204 - recall_2: 0.6169 - precision_2: 0.6169 - auc_2: 0.6821 - categorical_accuracy: 0.6169 - val_loss: 0.7251 - val_recall_2: 0.6200 - val_precision_2: 0.6200 - val_auc_2: 0.6887 - val_categorical_accuracy: 0.6200\n","Epoch 37/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7237 - recall_2: 0.6244 - precision_2: 0.6244 - auc_2: 0.6698 - categorical_accuracy: 0.6244\n","Epoch 00037: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0037.ckpt\n","34/34 [==============================] - 16s 485ms/step - loss: 0.7237 - recall_2: 0.6244 - precision_2: 0.6244 - auc_2: 0.6698 - categorical_accuracy: 0.6244 - val_loss: 0.7251 - val_recall_2: 0.6200 - val_precision_2: 0.6200 - val_auc_2: 0.6880 - val_categorical_accuracy: 0.6200\n","Epoch 38/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7307 - recall_2: 0.6169 - precision_2: 0.6169 - auc_2: 0.6621 - categorical_accuracy: 0.6169\n","Epoch 00038: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0038.ckpt\n","34/34 [==============================] - 16s 484ms/step - loss: 0.7307 - recall_2: 0.6169 - precision_2: 0.6169 - auc_2: 0.6621 - categorical_accuracy: 0.6169 - val_loss: 0.7250 - val_recall_2: 0.6200 - val_precision_2: 0.6200 - val_auc_2: 0.6877 - val_categorical_accuracy: 0.6200\n","Epoch 39/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7286 - recall_2: 0.6020 - precision_2: 0.6020 - auc_2: 0.6590 - categorical_accuracy: 0.6020\n","Epoch 00039: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0039.ckpt\n","34/34 [==============================] - 17s 487ms/step - loss: 0.7286 - recall_2: 0.6020 - precision_2: 0.6020 - auc_2: 0.6590 - categorical_accuracy: 0.6020 - val_loss: 0.7249 - val_recall_2: 0.6200 - val_precision_2: 0.6200 - val_auc_2: 0.6898 - val_categorical_accuracy: 0.6200\n","Epoch 40/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7318 - recall_2: 0.6269 - precision_2: 0.6269 - auc_2: 0.6562 - categorical_accuracy: 0.6269\n","Epoch 00040: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0040.ckpt\n","34/34 [==============================] - 17s 489ms/step - loss: 0.7318 - recall_2: 0.6269 - precision_2: 0.6269 - auc_2: 0.6562 - categorical_accuracy: 0.6269 - val_loss: 0.7248 - val_recall_2: 0.6200 - val_precision_2: 0.6200 - val_auc_2: 0.6898 - val_categorical_accuracy: 0.6200\n","Epoch 41/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7183 - recall_2: 0.6169 - precision_2: 0.6169 - auc_2: 0.6788 - categorical_accuracy: 0.6169\n","Epoch 00041: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0041.ckpt\n","34/34 [==============================] - 17s 493ms/step - loss: 0.7183 - recall_2: 0.6169 - precision_2: 0.6169 - auc_2: 0.6788 - categorical_accuracy: 0.6169 - val_loss: 0.7247 - val_recall_2: 0.6200 - val_precision_2: 0.6200 - val_auc_2: 0.6902 - val_categorical_accuracy: 0.6200\n","Epoch 42/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7318 - recall_2: 0.6119 - precision_2: 0.6119 - auc_2: 0.6452 - categorical_accuracy: 0.6119\n","Epoch 00042: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0042.ckpt\n","34/34 [==============================] - 17s 491ms/step - loss: 0.7318 - recall_2: 0.6119 - precision_2: 0.6119 - auc_2: 0.6452 - categorical_accuracy: 0.6119 - val_loss: 0.7246 - val_recall_2: 0.6200 - val_precision_2: 0.6200 - val_auc_2: 0.6894 - val_categorical_accuracy: 0.6200\n","Epoch 43/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7245 - recall_2: 0.6343 - precision_2: 0.6343 - auc_2: 0.6758 - categorical_accuracy: 0.6343\n","Epoch 00043: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0043.ckpt\n","34/34 [==============================] - 17s 486ms/step - loss: 0.7245 - recall_2: 0.6343 - precision_2: 0.6343 - auc_2: 0.6758 - categorical_accuracy: 0.6343 - val_loss: 0.7246 - val_recall_2: 0.6200 - val_precision_2: 0.6200 - val_auc_2: 0.6894 - val_categorical_accuracy: 0.6200\n","Epoch 44/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7211 - recall_2: 0.6244 - precision_2: 0.6244 - auc_2: 0.6822 - categorical_accuracy: 0.6244\n","Epoch 00044: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0044.ckpt\n","34/34 [==============================] - 17s 490ms/step - loss: 0.7211 - recall_2: 0.6244 - precision_2: 0.6244 - auc_2: 0.6822 - categorical_accuracy: 0.6244 - val_loss: 0.7245 - val_recall_2: 0.6200 - val_precision_2: 0.6200 - val_auc_2: 0.6898 - val_categorical_accuracy: 0.6200\n","Epoch 45/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7335 - recall_2: 0.6070 - precision_2: 0.6070 - auc_2: 0.6422 - categorical_accuracy: 0.6070\n","Epoch 00045: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0045.ckpt\n","34/34 [==============================] - 17s 487ms/step - loss: 0.7335 - recall_2: 0.6070 - precision_2: 0.6070 - auc_2: 0.6422 - categorical_accuracy: 0.6070 - val_loss: 0.7245 - val_recall_2: 0.6200 - val_precision_2: 0.6200 - val_auc_2: 0.6899 - val_categorical_accuracy: 0.6200\n","Epoch 46/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7214 - recall_2: 0.6443 - precision_2: 0.6443 - auc_2: 0.6845 - categorical_accuracy: 0.6443\n","Epoch 00046: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0046.ckpt\n","34/34 [==============================] - 18s 538ms/step - loss: 0.7214 - recall_2: 0.6443 - precision_2: 0.6443 - auc_2: 0.6845 - categorical_accuracy: 0.6443 - val_loss: 0.7245 - val_recall_2: 0.6200 - val_precision_2: 0.6200 - val_auc_2: 0.6899 - val_categorical_accuracy: 0.6200\n","Epoch 47/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7176 - recall_2: 0.6244 - precision_2: 0.6244 - auc_2: 0.6864 - categorical_accuracy: 0.6244\n","Epoch 00047: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0047.ckpt\n","34/34 [==============================] - 17s 490ms/step - loss: 0.7176 - recall_2: 0.6244 - precision_2: 0.6244 - auc_2: 0.6864 - categorical_accuracy: 0.6244 - val_loss: 0.7245 - val_recall_2: 0.6200 - val_precision_2: 0.6200 - val_auc_2: 0.6900 - val_categorical_accuracy: 0.6200\n","Epoch 48/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7256 - recall_2: 0.6169 - precision_2: 0.6169 - auc_2: 0.6706 - categorical_accuracy: 0.6169\n","Epoch 00048: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0048.ckpt\n","34/34 [==============================] - 17s 488ms/step - loss: 0.7256 - recall_2: 0.6169 - precision_2: 0.6169 - auc_2: 0.6706 - categorical_accuracy: 0.6169 - val_loss: 0.7245 - val_recall_2: 0.6200 - val_precision_2: 0.6200 - val_auc_2: 0.6905 - val_categorical_accuracy: 0.6200\n","Epoch 49/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7265 - recall_2: 0.6343 - precision_2: 0.6343 - auc_2: 0.6706 - categorical_accuracy: 0.6343\n","Epoch 00049: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0049.ckpt\n","34/34 [==============================] - 17s 490ms/step - loss: 0.7265 - recall_2: 0.6343 - precision_2: 0.6343 - auc_2: 0.6706 - categorical_accuracy: 0.6343 - val_loss: 0.7245 - val_recall_2: 0.6200 - val_precision_2: 0.6200 - val_auc_2: 0.6907 - val_categorical_accuracy: 0.6200\n","Epoch 50/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7179 - recall_2: 0.6493 - precision_2: 0.6493 - auc_2: 0.6927 - categorical_accuracy: 0.6493\n","Epoch 00050: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0050.ckpt\n","34/34 [==============================] - 17s 490ms/step - loss: 0.7179 - recall_2: 0.6493 - precision_2: 0.6493 - auc_2: 0.6927 - categorical_accuracy: 0.6493 - val_loss: 0.7245 - val_recall_2: 0.6200 - val_precision_2: 0.6200 - val_auc_2: 0.6907 - val_categorical_accuracy: 0.6200\n","Epoch 51/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7297 - recall_2: 0.6020 - precision_2: 0.6020 - auc_2: 0.6530 - categorical_accuracy: 0.6020\n","Epoch 00051: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0051.ckpt\n","34/34 [==============================] - 17s 490ms/step - loss: 0.7297 - recall_2: 0.6020 - precision_2: 0.6020 - auc_2: 0.6530 - categorical_accuracy: 0.6020 - val_loss: 0.7245 - val_recall_2: 0.6200 - val_precision_2: 0.6200 - val_auc_2: 0.6907 - val_categorical_accuracy: 0.6200\n","Epoch 52/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7302 - recall_2: 0.5995 - precision_2: 0.5995 - auc_2: 0.6564 - categorical_accuracy: 0.5995\n","Epoch 00052: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0052.ckpt\n","34/34 [==============================] - 17s 486ms/step - loss: 0.7302 - recall_2: 0.5995 - precision_2: 0.5995 - auc_2: 0.6564 - categorical_accuracy: 0.5995 - val_loss: 0.7245 - val_recall_2: 0.6200 - val_precision_2: 0.6200 - val_auc_2: 0.6907 - val_categorical_accuracy: 0.6200\n","Epoch 53/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7274 - recall_2: 0.6070 - precision_2: 0.6070 - auc_2: 0.6517 - categorical_accuracy: 0.6070\n","Epoch 00053: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0053.ckpt\n","34/34 [==============================] - 17s 488ms/step - loss: 0.7274 - recall_2: 0.6070 - precision_2: 0.6070 - auc_2: 0.6517 - categorical_accuracy: 0.6070 - val_loss: 0.7245 - val_recall_2: 0.6200 - val_precision_2: 0.6200 - val_auc_2: 0.6907 - val_categorical_accuracy: 0.6200\n","Epoch 54/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7236 - recall_2: 0.6144 - precision_2: 0.6144 - auc_2: 0.6631 - categorical_accuracy: 0.6144\n","Epoch 00054: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0054.ckpt\n","34/34 [==============================] - 17s 491ms/step - loss: 0.7236 - recall_2: 0.6144 - precision_2: 0.6144 - auc_2: 0.6631 - categorical_accuracy: 0.6144 - val_loss: 0.7244 - val_recall_2: 0.6200 - val_precision_2: 0.6200 - val_auc_2: 0.6901 - val_categorical_accuracy: 0.6200\n","Epoch 55/200\n","34/34 [==============================] - ETA: 0s - loss: 0.7287 - recall_2: 0.6020 - precision_2: 0.6020 - auc_2: 0.6631 - categorical_accuracy: 0.6020\n","Epoch 00055: saving model to /content/gdrive/My Drive/checkpoints/20201126-224007/cp-0055.ckpt\n","34/34 [==============================] - 17s 491ms/step - loss: 0.7287 - recall_2: 0.6020 - precision_2: 0.6020 - auc_2: 0.6631 - categorical_accuracy: 0.6020 - val_loss: 0.7244 - val_recall_2: 0.6200 - val_precision_2: 0.6200 - val_auc_2: 0.6907 - val_categorical_accuracy: 0.6200\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-96-03f0d1394089>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\nif not USE_TPU and TRAIN_MODEL:\\n  # tf.executing_eagerly()\\n  \\n  \\n  model, checkpoint_dir, history = train(\\n      model,\\n      train_seq,\\n      val_seq,\\n      **train_config\\n  )'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n","\u001b[0;32m<ipython-input-91-a2e8609e4e34>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_seq, val_seq, tpu, validation, epochs, patience, model_key, tensorboard_update_freq, mri_tensorboard_callback, model_checkpoint_callback, batch_size, workers)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;31m# class_weight=class_weight,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         callbacks=callbacks)\n\u001b[0m\u001b[1;32m     97\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training on tpu...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1084\u001b[0m       data_handler._initial_epoch = (  # pylint: disable=protected-access\n\u001b[1;32m   1085\u001b[0m           self._maybe_load_initial_epoch_from_ckpt(initial_epoch))\n\u001b[0;32m-> 1086\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1087\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1141\u001b[0m           \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_recreate_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m           \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    413\u001b[0m     \"\"\"\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec, job_token)\u001b[0m\n\u001b[1;32m    694\u001b[0m           context.context().device_spec.device_type != \"CPU\"):\n\u001b[1;32m    695\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/cpu:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    700\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0;31m# Store dataset reference to ensure that dataset is alive when this iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_apply_options\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    385\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         dataset = _OptimizeDataset(dataset, graph_rewrites,\n\u001b[0;32m--> 387\u001b[0;31m                                    graph_rewrite_configs)\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[0;31m# (3) Apply autotune options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, optimizations, optimization_configs)\u001b[0m\n\u001b[1;32m   4398\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4399\u001b[0m         \u001b[0moptimization_configs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimization_configs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4400\u001b[0;31m         **self._flat_structure)\n\u001b[0m\u001b[1;32m   4401\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_OptimizeDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36moptimize_dataset\u001b[0;34m(input_dataset, optimizations, output_types, output_shapes, optimization_configs, name)\u001b[0m\n\u001b[1;32m   3946\u001b[0m         \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_types\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3947\u001b[0m         \u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_shapes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"optimization_configs\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3948\u001b[0;31m         optimization_configs)\n\u001b[0m\u001b[1;32m   3949\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3950\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"Xc4RSSyQ6qS6"},"source":["### TPU"]},{"cell_type":"code","metadata":{"id":"4eW4wxWYJcfi"},"source":["import tensorflow as tf\n","import os\n","\n","tf.executing_eagerly()\n","tf.keras.backend.clear_session()\n","\n","      \n","if USE_TPU:\n","  tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n","\n","  cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=tpu_address)\n","\n","  tf.config.experimental_connect_to_cluster(cluster_resolver)\n","  tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n","\n","  print(\"All devices: \", tf.config.list_logical_devices('TPU'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t-IWpa316p8j"},"source":["# TPU Support\n","# https://towardsdatascience.com/how-to-colab-with-tpu-98e0b4230d9c\n","\n","if USE_TPU:\n","  strategy = tf.distribute.TPUStrategy(cluster_resolver)\n","\n","  with strategy.scope():\n","    model = create_model(**model_config)\n","    model, optimizer = compile_model(model, **compile_config)\n","    model.build(input_shape=input_shape)\n","    model.summary()\n","  \n","BATCH_SIZE_PER_REPLICA = batch_size # strategy.num_replicas_in_sync\n","print(f'BATCH_SIZE_PER_REPLICA {BATCH_SIZE_PER_REPLICA}')\n","print(model_config)\n","print(compile_config)\n","print(train_config)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"icWdb6cd8dAx"},"source":["if USE_TPU and not TRAIN_MODEL:\n","  with strategy.scope():\n","    load_checkopint(model, DEFAULT_TPU_CHECKPOINT_DIRECTORY, '20201110-143615', 'cp-0067.ckpt', tf.train.CheckpointOptions(experimental_io_device=\"/localhost:job\"))  \n","\n","# with strategy.scope():\n","#   load_checkopint(model, DEFAULT_LOCAL_BCKP_CHECKPOINT_DIRECTORY, '20201110-143615', 'cp-0067.ckpt', tf.train.CheckpointOptions(experimental_io_device=\"/localhost:job\"))  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g9OWy1159ILi"},"source":["%%time\n","\n","if USE_TPU and TRAIN_MODEL:\n","  model, checkpoint_dir, history = train(\n","      model,\n","      train_seq,\n","      val_seq,\n","      **train_config\n","  )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UITXSlmrY_ou"},"source":["## Evaulation"]},{"cell_type":"code","metadata":{"id":"6GBmHOW_upFK"},"source":["if TRAIN_MODEL:\n","  plot_training_history(history)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L8LqNQdr19Sa"},"source":["%%time\n","\n","# not working because of sequence\n","if not USE_TPU:\n","  show_simple_metrics(model, test_seq)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hv43nH5Lu7XF"},"source":["%%time\n","\n","show_metrics(model, test_seq)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1TZocfC9_ZJV"},"source":["# show_checkpoint_metrics(model, test_seq, 71)"],"execution_count":null,"outputs":[]}]}